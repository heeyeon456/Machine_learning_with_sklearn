{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Model\n",
    "## 1.Least Square\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "어떠한 데이터가 주어졌을 때 그 데이터는 수식으로 표현될 수 있다.\n",
    "예를 들어 집값이라는 반응변수가 주어졌을 때 이는 교통편, 주변환경 시설, 집의 넓이, 기본제공 가구목록 등 여러가지 설명변수로 표현될 수 있다.\n",
    "그리고 우리는 모든 데이터를 관찰할 수 없기 때문에 내가 관찰한 데이터를 가지고 집값(y)라는 변수는 여러가지(x)값들과 주어진 설명변수로 표현할 수 없는 값(error)값으로 표현할 수 있다. \n",
    "\n",
    "$$ y  = \\sum_{i=0}^n a_ix_i+e_i $$\n",
    "\n",
    "하지만 우리는 설명변수가 주어졌을 때 모든 데이터에 대한 반응변수를 예측할 수 있는 general한 식을 얻고 싶다. \n",
    "**머신러닝**은 이처럼 probably approximately correct한 function을 주어진 데이터를 가지고 찾아나가는 과정을 의미한다.\n",
    "General model을 찾아나가는데 중요한 것은 most probable한 parameter를 찾아가는 것이다.\n",
    "여기서 가장 간단한 접근 방법이 **least square**접근법이다.\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{a} = argmin(f-\\hat{f}) = argmin_\\theta (Y-aX)^2\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tools import rmse_cal,mae_cal,cor_cal,mean_cal,frange,\\\n",
    "                    accuracy,precision,recall,aupr,f1_score,make_binary\n",
    "from validation import classification_cv,regression_cv,external_val_reg,\\\n",
    "                        external_val_classif, test_preprocessing, cal_auc, \\\n",
    "                        draw_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##dataset\n",
    "dataset=pd.read_table('data/blood_age_selected_mutual_info.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=dataset.T.fillna(dataset.mean(axis=1)).T\n",
    "dataset.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_t=dataset.iloc[:,1:].transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_data = data_t.iloc[:,:-1]\n",
    "y_data = data_t.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reg = LinearRegression(n_jobs=20)\n",
    "cv_result=regression_cv(10,reg,dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df=pd.read_table('data/blood_age_test.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_result=external_val_reg(test_df,dataset,reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principle of parsimony (Occam's Razor) ##\n",
    "---\n",
    "- 간결한 모델일 수록 좋다.<br/>\n",
    "어떤 실험 결과나 현상에 대해 설명할 수 있는 변수들이 많은 경우 그것을 가장 잘 설명할 수 있는 변수는 결국 간단한 설명 혹은 최소한 의 설명이 되는 변수로 이루어진 모델이다.<br/><br/>\n",
    "- **subset selection** : 중요한 변수를 선정하고, 중요하지 않은 변수를 버리는 작업<br/>\n",
    "머신러닝에서의 feature selection<br/><br/>\n",
    "- **shrinkage** : 중요하지 않은 변수에 해당하는 Coefficient의 절대값을 낮추는 것\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Regularization ##\n",
    "---\n",
    "=shrinkage\n",
    "\n",
    "기계학습에서는 **bias - variance trade off** 문제가 종종 발생한다.<br/><br/>\n",
    "**bias**는 데이터 내의 모든 정보를 잘 반영하지 않아 잘못된 것을 학습하는 경향이다. (= **Underfitting**) <br/>\n",
    "**Variance**는 데이터 내에 존재하는 error나 noise까지 학습에 반영되어 training data에 너무 적합한 모델이 학습되는 경향이다. 이는 **overfitting**과 관련이 있다. -> 앞 0.basis예시 참고 <br/>\n",
    "<br/><br/><br/>\n",
    "특히 overfitting 문제는 machine learning에서 종종 발생하고, 이를 해결하기 위한 방법으로는 **regularization**이 있다.<br/><br/>\n",
    "\n",
    "예를 들어 4차 함수의 linear regression에 대한 hypothesis function이 다음과 같다고 하자<br/>\n",
    "$$ y=\\theta_0 + \\theta_1 x+ \\theta_2 x^2 + \\theta_3 x^3 + \\theta_4 x^4 $$ <br/>\n",
    "하지만 이 함수는 데이터를 설명하는데에 있어서 overfitting문제를 가지고 있다고 할 때, 3승과 4승에 해당하는 항의 영향을 줄여 overfitting문제를 개선하고자 한다. <br/><br/>\n",
    "이를 해결하기 위해서는 cost function을 수정하면 된다. <br/>\n",
    "$$ min \\frac{1}{2m} \\sum_{i=1}^{m}(h_0(x^{(i)})-y^{(i)})^2 + 1000\\theta _3^2 + 1000\\theta _4^2 $$<br/>\n",
    "\n",
    "cost function을 이렇게 수정한다면 최소한의 cost를 가지는 각 파라미터 세타 값을 구할 때에 x^3과 x^4의 계수는 매우 작아질 것이다.\n",
    "이러한 방식으로 x^3과 x^4에 해당하는 계수의 값을 줄여 overfitting을 방지할 수 있다. <br/>\n",
    "<br/><br/>\n",
    "이를 일반적인 수식으로 나타내면 다음과 같다.<br/>\n",
    "$$ min_\\theta \\frac{1}{2m}[ \\sum_{i=1}^{m}(h_0(x^{(i)})-y^{(i)})^2 + \\lambda \\sum_{i=1}^{n}\\theta_j^2]  $$<br/>\n",
    "\n",
    "위의 cost function에서 두번째 항을 regularization term이라고 하고, lambda를 regularization parameter라고 한다.<br/><br/>\n",
    "lambda가 너무 크면 모든 항들에 대하서 너무 많이 penalty가 적용되므로 model이 데이터를 잘 설명하지 못하는 underfitting문제가 발생할 것이다.<br/><br/> 하지만 lambda가 너무 작으면 모든 항들에 대해서 penalty가 적용되지 않으므로 overfitting문제가 계속 발생할 것이다. <br/><br/>\n",
    "따라서 적절한 lambda를 선택하는 것이 매우 중요하다.<br/><br/>\n",
    "[참고](http://gnujoow.github.io/ml/2016/01/30/ML4-Regularization/)<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression\n",
    "---\n",
    "ridge regression에서는 L2 norm인 Euclidean norm을 사용하여 패널티를 주는 방식을 선택하여 사용한다.<br/>\n",
    "\n",
    "\n",
    "$$L(\\beta)=\\frac{1}{2}(y-X\\beta )^T(y-X\\beta )+\\frac{\\lambda }{2}||\\beta ||^2_2 $$\n",
    "\n",
    "$$ ||\\beta||^2 = \\sqrt{\\beta _1^2 + \\beta _2^2 + ... +\\beta _n^2} $$\n",
    "\n",
    "ridge regression의 cost function은 기존의 회귀분석의 RSS(Residual Sum of Square)항과 패널티 항 두 항의 합으로 이루어져 있다.<br/><br/>\n",
    "이러한 ridge regression은 기존 선형회귀의 RSS를 최소화하는 beta값이더라고 구한 beta값의 크기가 너무 크면 그에 대한 패널티를 부여해 cost function값을 높여버린다.  <br/>\n",
    "\n",
    "$$ min_w||Xw-y||_2^2+\\alpha ||w||_2^2 $$<br/>\n",
    "\n",
    "alpha는 shrinkage의 정도를 조절해주는 parameter<br/>\n",
    "\n",
    "[참고](http://r-programming.club/14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tools import rmse_cal,mae_cal,cor_cal,mean_cal,frange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf=KFold(n_splits=10,shuffle=True)\n",
    "ridge=RidgeCV(alphas=(0.1, 1.0, 10.0), fit_intercept=True, scoring=None ,cv=kf,gcv_mode='auto')\n",
    "# alpha : number of alpha to test 여기서는 0.1부터 1까지 10개의 alpha값을 cross validation으로 고르고자 한다.\n",
    "# fit_intercept : 이모델의 intercept(절편을 계산할껀지)\n",
    "# normalize : regression모델을 만들기 전에 normalize할껀지\n",
    "#gcv_mode : generalized cross validation option "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse : 5.02860328084\n",
      "mad : 3.73462748276\n",
      "cor : 0.93991613812\n"
     ]
    }
   ],
   "source": [
    "cv_result=regression_cv(10,ridge,dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.59091989,   2.49656582,   1.44826133,  -1.87980952,\n",
       "        -1.21974143,   3.74495556,   5.08736083,   0.07263866,\n",
       "        -0.05788845,   0.27041832,  -0.33505452,  -5.99500989,\n",
       "        -1.08411416,  -4.21570477,   0.96206366,   0.85652528,\n",
       "        -0.59934286,   6.72064051,   0.82543246,  -3.75117776,\n",
       "        -4.17478571,   0.45407288,  -3.64490632,   2.49735738,\n",
       "         5.16672612,   2.51115409,   5.68778448,   1.36566965,\n",
       "         0.29154902,   1.87048859,   7.56294939,  -3.01025306,\n",
       "         5.72448426,  -4.26465899,   3.49628842,   0.24085303,\n",
       "        -1.56236546,  -0.11096576,  -0.5083323 ,   6.72334306,\n",
       "        -4.66189645,  -0.05394871,   4.0586779 ,  -8.18057901,\n",
       "         4.51722247,   1.28500279,   1.33771589,   2.28191524,\n",
       "         0.55702845,   0.42998684,   3.20293915,   5.0952437 ,\n",
       "        -2.34586184,   2.0842783 ,   1.97035104,   2.10649233,\n",
       "        -7.42258141,  -3.07282926,  -4.97929389,  -1.29067848,\n",
       "         5.5832078 ,   7.3699447 ,   1.51114109,   0.06997618,\n",
       "        -5.14104994,  -5.42369973,  -3.31721168,   4.79164026,\n",
       "         2.8064385 ,   5.44539272,   3.63097616,  -1.78396793,\n",
       "        -0.51819618,   9.30681881,   2.81871604,  11.05398181,\n",
       "        -3.22211513,   5.58272432,  -1.97875183,   2.24586282,\n",
       "        -0.42786913,   2.15241019,  -1.92716266,   0.54253806,\n",
       "        -0.59248063,  -0.39404817,  -0.70531978,  -2.77860965,\n",
       "        -6.94640092,  -2.96288651,   1.10846108, -13.97166333,\n",
       "        -0.91644508,   2.79491175,   1.36667419,  -0.89493964,\n",
       "        -2.87358978,  -6.52849143,   1.26326749,   2.65127651,\n",
       "        -0.33268239,   1.17514631,   0.75876505,  -2.52835462,\n",
       "         0.17322125,  -1.49453172,  -0.39843567,  -0.20908123,\n",
       "        -1.70762872,   0.43288432,   3.4307819 ,  -2.10146112,\n",
       "         0.22592834,  -6.23112225,  -7.72768438,  13.78422286,\n",
       "        -0.03242781,  -0.94335067,   8.00559109,   5.71963299,\n",
       "         1.41075141,  -0.84917331,   2.54497392,  -0.81217709,\n",
       "        -0.32965009,  -4.01033573,  -0.40303318,  -3.83304662,\n",
       "        -5.86189886,  -1.76345543,   2.89202649,  -5.53242431,\n",
       "         2.19595517,   2.47327526,   5.03916139,   0.73849116,\n",
       "         4.39520797,   2.41740891,   6.42065464,  -0.0435558 ,\n",
       "        -0.3639972 ,  17.54917122,  -3.24160457,   4.18104578,\n",
       "         6.43324685,  -3.8530999 ,   1.90178799,   0.06755218,\n",
       "         1.51081865,   2.85939427,  -1.97205694,  -0.53542786,\n",
       "        -0.23439422,  -0.76259044,   2.45986229,  -5.33253128,\n",
       "         0.59101061,  -4.39296716,  -7.7443489 ,   1.86866828,\n",
       "         1.28892567,   1.03436347,   2.80085617,  -1.8006214 ,\n",
       "         2.25125853,  -5.13372199,  -1.83972401,  -1.5253222 ,\n",
       "        -1.40151735,  -0.4191712 ,   3.40242824,   4.21347417,\n",
       "         3.58394203,  -1.65101613,  -2.26729881,  -1.15254263,\n",
       "         2.01901666,   0.04600588,   6.04017792,   5.67414698,\n",
       "        -2.57473392,   1.67471806,   2.04752956,  -4.44223675,\n",
       "         4.45881784,   4.69014145,  -6.58436527,  -1.67388266,\n",
       "         3.47970943,   8.69237722,   2.71669815,   3.48010973,\n",
       "        -0.67917221,   8.5047595 ,  -0.67131611,   4.79238412,\n",
       "        -0.13334243,  -5.8696744 ,  -4.92540522,  -5.71165247,\n",
       "        -5.97673874,   1.333024  ,  -1.51510248,   8.49701421,\n",
       "         0.38566427,  -5.6317005 ,   3.44141111,   0.16446041,\n",
       "        -1.48494381,   5.69332479,  -2.80915371,   3.99629605,\n",
       "        -0.52040691,   2.05130964,   1.92017122,  -3.23477628,\n",
       "        -0.87609206,   0.72273144,   3.37048336,   3.66609316,\n",
       "         1.6425181 ,  -0.42820795,   3.46671135,   5.00893926,\n",
       "         5.36221682,   0.54036798,   1.50027023,  -1.81493881,\n",
       "         0.09156213,  -5.33792938,   1.06143282,   6.1069237 ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reg_coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_result=external_val_reg(test_df,dataset,ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression ##\n",
    "---\n",
    "Lasso regression은 ridge regression의 장점인 회귀계수 축소를 통해 예측 정확도를 높이고(shrinkage), 동시에 영향력이 적은 회귀계수의 값을 쉽게 0으로 만드는 변수 선택의 기능이 있어(subset selection)의 기능이 있어 해석력을 높여준다.<br/>\n",
    "Lasso regression은 l1 norm을 사용해서 패널티를 주는 방식을 이용한다.<br/><br/>\n",
    "\n",
    "Lasso regression의 추정량의 식은 다음과 같다.<br/>\n",
    "\n",
    "$$ argmin_{\\beta_1,...,\\beta_p}\\left \\{\\sum_{i=1}^{n}(Y_i-\\beta_0-\\sum_{j=1}^{p}\\beta_jx_{ij})^2 + \\lambda \\sum_{j=1}^{p}|\\beta_j|  \\right \\}  $$ <br/>\n",
    "\n",
    "위 식은 다음과 같은 제약조건이 주어진 최소화(minimization)문제로 표시할 수 있다.<br/><br/>\n",
    "$$argmin_{\\beta_1,...,\\beta_p}\\left \\{\\sum_{i=1}^{n}(Y_i-\\beta_0-\\sum_{j=1}^{p}\\beta_jx_{ij})^2\\right \\} subject to \\sum_{j=1}^{p}|\\beta_j|\\leq t$$<br/>\n",
    "\n",
    "위 식의 제약 조건인 t는 회귀계수 값에 대하여 축소 정도를 조절하는 tuning parameter이다. <br/><br/>이 tuning parameter t값이 줄어들지 않으면 중요하지 않은 변수의 회귀계수 값은 축소되면서 순서대로 0으로 만들어져 변수 선택이 되는 효과가 생긴다.<br/><br/>\n",
    "만약 t값이 충분히 커지면 회귀 계수에 대한 제약이 없어지므로 RSS부분만 남아 Lasso 회귀추정량이 최소제곱 추정량이 된다.<br/><br/>\n",
    "\n",
    "\n",
    "$$ min_w||Xw-y||_2^2+\\alpha ||w||_1 $$\n",
    "\n",
    "||w||는 l1-norm의 parameter vector<br/>\n",
    "\n",
    "[참고](http://m.blog.daum.net/naturelove87/154)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "\n",
    "from numpy.random import RandomState\n",
    "from numpy import nonzero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lasso=LassoCV(eps=0.01, n_alphas=100, fit_intercept=True, max_iter=1000, tol=0.0001, cv=kf, n_jobs=10, positive=False, random_state=RandomState(None), selection='random')\n",
    "#eps : alpha_min / alpha_max, 비교해야할 alpha의 최소값과 최대값의 비율\n",
    "#n_alphas : regularization과정에서 test할 alpha의 개수\n",
    "#tol : optimization을 언제까지 진행깔껀지, 만약 performance가 tol보다 적게 향상됬다면 optimazation을 하지 않는다,\n",
    "#positive : True이면 regression coefficient가 양수가 되도록 조정한다\n",
    "#random_state : random state를 특정 값으로 설정해 놓으면 pseudo random generator가 특정 값에 해당하는 random number를 generate해준다\n",
    "#특정 seed에 대해서 생성되는 random number는 항상 동일하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[참고 : pseudo random number generator](https://en.wikipedia.org/wiki/Pseudorandom_number_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse : 5.42047498777\n",
      "mad : 3.9623456958\n",
      "cor : 0.9298017785\n"
     ]
    }
   ],
   "source": [
    "cv_result=regression_cv(10,lasso,dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lasso.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of reduced feature using lasso :53\n",
      "original number of feature : 232\n"
     ]
    }
   ],
   "source": [
    "lasso.fit(X_data, y_data)\n",
    "tmp=dataset.iloc[:-1,:]\n",
    "print('number of reduced feature using lasso :' + str(len(tmp[lasso.coef_!=0])))\n",
    "print('original number of feature : '+str(len(tmp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_result=external_val_reg(test_df,dataset,lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic Net Regression ##\n",
    "---\n",
    "ElasticNet은 L1과 ㅣ2를 모두 regularizer로 이용하는 linear regression model이다.<br/><br/> 이 조합은 Lasso에서 weight를 0으로 만드는 subset selection 방법을 통해 sparse한 모델을 만드는 특징과 ridge에서의 shrinkage를 이용한 regularization property를 유지하는 특징을 지닌다. <br/><br/>이 방법에서는 L1과 L2의 값을 l1_ratio라는 parameter를 이용해 그 정도를 조절한다.<br/><br/><br/>\n",
    "ElasticNet의 추정량 식은 다음과 같다<br/>.\n",
    "\n",
    "$$ min_w\\frac{1}{2n}||Xw-y||^2_2+\\alpha \\beta ||w||_1+\\frac{\\alpha (1-\\beta )}{2}||w||_2^2 $$<br/>\n",
    "\n",
    "여기서 alpha는 penalty를 얼마나 줄것인가에 대한 parameter이고 beta(l1_ratio)는 lasso와 ridge를 얼마만큼의 비율로 적용할 것인가에 대한 parameter이다.<br/><br/>\n",
    "\n",
    "ElasticNet은 서로 연관이 되어잇는 multiple feature를 다루는데 유용하고, dataset개수에 비해 feature수가 매우 많을 때 가장 잘 learning되는 regression model로 알려져있다.<br/><br/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from numpy.random import RandomStatea\n",
    "from numpy import nonzero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def elastic_net_l1(input_data,l1):\n",
    "    \"\"\"elastic net 10-fold crossvalidation\"\"\"\n",
    "    \n",
    "    kf=KFold(n_splits=10,shuffle=True)\n",
    "    input_t=input_data.ix[:,1:]\n",
    "    final_input=input_t.transpose()\n",
    "    \n",
    "        \n",
    "    pred=pd.DataFrame()\n",
    "    real=pd.DataFrame()\n",
    "    \n",
    "    elastic_net=ElasticNetCV(cv=kf, fit_intercept=True, random_state=RandomState(None), selection='random',\n",
    "                             max_iter=100000,l1_ratio=l1)\n",
    "    \n",
    "    prediction=pd.DataFrame(columns=['predict','real'])\n",
    "\n",
    "    rmse=0\n",
    "    cor=0\n",
    "\n",
    "    for train, test in kf.split(final_input):\n",
    "            \n",
    "        x_train=final_input.iloc[train,:-1].astype('float64').values\n",
    "        y_train=final_input.iloc[train,-1].astype('float64').values\n",
    "        elastic_net.fit(x_train,y_train)\n",
    "    \n",
    "        x_test=final_input.iloc[test,:-1].astype('float64').values\n",
    "        y_test=final_input.iloc[test,-1].astype('float64').values\n",
    "        \n",
    "        pred=pred.append(pd.DataFrame(elastic_net.predict(x_test)))\n",
    "        real=real.append(pd.DataFrame(y_test))\n",
    "        \n",
    "        prediction=pd.concat([pred,real],axis=1)\n",
    "\n",
    "        rmse=rmse+rmse_cal(prediction.iloc[:,0],prediction.iloc[:,1])\n",
    "        cor=cor+cor_cal(prediction.iloc[:,0],prediction.iloc[:,1])[0]\n",
    "    \n",
    "    rmse=rmse/10\n",
    "    cor=cor/10\n",
    "    \n",
    "    return l1,rmse,cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_l1(input_data):\n",
    "    \"\"\"elastic net has two parameter : alpha(amount of regularization) and l1_ratio(ratio of ridge and lasso regularization)\n",
    "       optimal alpha can be found automatically using ElasticNetCV.\n",
    "       we should find optimal l1 ratio using 10-fold cross validation.\"\"\"\n",
    "       \n",
    "    \"\"\"choose elastic net l1 ratio\"\"\"\n",
    "    \n",
    "    list=['l1','rmse','cor']\n",
    "    by_l1_ratio=pd.DataFrame(columns=list)\n",
    "    num=0\n",
    "    for l in frange(0.1,1,0.1):\n",
    "        el=elastic_net_l1(input_data,l)\n",
    "        by_l1_ratio.loc[num]=el\n",
    "         \n",
    "        num=num+1\n",
    "    print(by_l1_ratio)\n",
    "    \n",
    "    return by_l1_ratio.loc[by_l1_ratio['rmse'].idxmin()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l1_ratio=find_l1(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf=KFold(n_splits=10,shuffle=True)\n",
    "elasticnet=ElasticNetCV(cv=kf, fit_intercept=True, random_state=RandomState(None), selection='random',\n",
    "                             max_iter=100000,l1_ratio=l1_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "elasticnet.fit(X_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp=dataset.iloc[:-1,:]\n",
    "print('number of reduced feature using ElasticNet :' + str(len(tmp[elasticnet.coef_!=0])))\n",
    "print('number of reduced feature using lasso :' + str(len(tmp[lasso.coef_!=0])))\n",
    "print('original number of feature : '+str(len(tmp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_result=external_val_reg(test_df,dataset,elasticnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression ##\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistic Regression은 종속 변수가 categorical할 때 쓰는 회귀 모델이다.<br/><br/>\n",
    "- Logistic Regression의 목적은 두개의 범주가 주어졌을 때 데이터를 이용해서 두 그룹 중 어떤 그룹에 속하는지 분류하고자 한다.\n",
    "<br/><br/><br/>\n",
    "우선 binary data가 주어졌을 때 이 binary data는 sample size가 1인 binomial trial에서부터 온 값이라고 가정한다.<br/><br/>\n",
    "$$ P(y)=p^y(1-p)^{1-y} $$<br/>\n",
    "binary data를 확률로 나타낼 수 있다면 오즈비(Odds Ratio)도 구할 수 있다.<br/><br/>\n",
    "**Odds Ratio** = 성공확률/실패확률 = p / 1-p<br/><br/>\n",
    "$$ Odds\\, Ratio = \\frac{p}{1-p} $$<br/>\n",
    "$$ Logit(p) = ln\\frac{p}{1-p} $$\n",
    "<br/><br/><br/>\n",
    "- logistic regression은 classification문제를 다루기 때문에 binary data가 A라는 class에 속할 확률(p)가 0.5이상이면 A class에 분류하고자 하고, 그렇지 않으면 B class에 분류하고자 한다.<br/><br/>\n",
    "- 따라서 logistic regression에서는 y가 나올 확률(p)를 선형회귀(ax+b)를 이용해서 계산하고자 한다.<br/><br/>\n",
    "1)logit함수를 선형회귀로 표현 $$ ln\\frac{p}{1-p} = ax+b $$<br/>\n",
    "2)양변에 e를 취함 $$ \\frac{p}{1-p}=e^{ax+b} $$<br/>\n",
    "3)양변에 1을 더함 $$ \\frac{1}{p}=\\frac{1+e^{ax+b}}{e^{ax+b}} $$<br/>\n",
    "4)역수를 취해서 확률을 계산하는 수식을 만듬 $$ p = \\frac{e^{ax+b}}{1+e^{ax+b}} $$<br/><br/>\n",
    "- 이렇게 y가 A class에 속한 확률을 나타낸 식을 로지스틱함수(logistic function)고 하고 이를 나타낸 곡선을 logistic curve라고 부른다.<br/><br/>\n",
    "![logistic](picture/logistic_regression.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "따라서 A class가 나올 확률 p가 0이면 x값은 -무한대가 되고, p=1이면 x값은 무한대가 되기 때문에 \n",
    "p=0에 가까울수록 0으로 보내주고, p가 1에 가까우면 1로 보내주어서 classification을 수행한다. 그리고 이러한 threshold를 적절하게 조정해가면서 찾게 된다.<br/><br/>\n",
    "$$ p=0 \\rightarrow  log(\\frac{p}{1-p})=-\\infty $$\n",
    "$$ p=1 \\rightarrow  log(\\frac{p}{1-p})=\\infty $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import KFold\n",
    "from numpy.random import RandomState\n",
    "from numpy import nonzero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model : Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf=KFold(n_splits=10,shuffle=True)\n",
    "logistic = LogisticRegressionCV(Cs=10, cv=kf, fit_intercept=True, dual=False, penalty='l2', \n",
    "        solver='sag', tol=0.0001, max_iter=100, n_jobs=20, verbose=0, refit=True, random_state=RandomState(None))\n",
    "#Cs : C값은 regularization정도와 반비례하고, Cs는 1e-4 and 1e4사이의 로그 스케일 값 중 몇개의 값을 테스트 할것 인지를 나타낸다.  \n",
    "#penalty : l1 norm또난 ㅣ2 norm을 이용할 것인지\n",
    "#solver : optimization algorithm들 \n",
    "#        liblinear : 데이터셋이 작을 때 좋다고 한다, sag : 클 때 좋다고 한다, \n",
    "##newton-cg, sag, lbfgs : multi class에서 쓰고, ㅣ2 penalty에서만 다룰수 있다.\n",
    "#dual : l2일 때만 True옵션이 가능하다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison for two feature selection method\n",
    "dataset1 : feature selected by mutual information using knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset1=pd.read_table('data/breast_cancer_mutual_info.tsv',sep='\\t')\n",
    "input_data=dataset1.iloc[:,1:].transpose()\n",
    "X_data=input_data.iloc[:,:-1].values\n",
    "y_data=input_data.iloc[:,-1]\n",
    "y_data=make_binary('normal','cancer',y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.9276649746192893\n",
      "precision :0.4631578947368421\n",
      "recall : 0.88\n",
      "f1_score : 0.6068965517241379\n"
     ]
    }
   ],
   "source": [
    "cv_test=classification_cv(10,logistic,dataset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#preprocessing for ROC curve\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=.2,random_state=RandomState(None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=10, class_weight=None,\n",
       "           cv=KFold(n_splits=10, random_state=None, shuffle=True),\n",
       "           dual=False, fit_intercept=True, intercept_scaling=1.0,\n",
       "           max_iter=100, multi_class='ovr', n_jobs=20, penalty='l2',\n",
       "           random_state=<mtrand.RandomState object at 0x7f9c5b535dc0>,\n",
       "           refit=True, scoring=None, solver='sag', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#각 sample들을 분류하기 위한 decision을 내리는 함수\n",
    "y_score=logistic.decision_function(X_test)\n",
    "fpr,tpr,threshold = roc_curve(y_test,y_score,pos_label=1)\n",
    "roc_auc=auc(fpr,tpr)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset2 : feature selection using svc with l1 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset2=pd.read_table('data/breast_cancer_svc.tsv',sep='\\t')\n",
    "input_data2=dataset2.iloc[:,1:].transpose()\n",
    "X_data2=input_data2.iloc[:,:-1].values\n",
    "y_data2=input_data2.iloc[:,-1]\n",
    "y_data2=make_binary('normal','cancer',y_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.998730964467005\n",
      "precision :0.9894736842105263\n",
      "recall : 1.0\n",
      "f1_score : 0.9947089947089947\n"
     ]
    }
   ],
   "source": [
    "cv_result=classification_cv(10,logistic,dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Preprocessing for ROC curve\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_data2, y_data2, test_size=.2,random_state=RandomState(None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=10, class_weight=None,\n",
       "           cv=KFold(n_splits=10, random_state=None, shuffle=True),\n",
       "           dual=False, fit_intercept=True, intercept_scaling=1.0,\n",
       "           max_iter=100, multi_class='ovr', n_jobs=20, penalty='l2',\n",
       "           random_state=<mtrand.RandomState object at 0x7f9c5b535dc0>,\n",
       "           refit=True, scoring=None, solver='sag', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic.fit(X_train2,y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#각 sample들을 분류하기 위한 decision을 내리는 함수\n",
    "y_score2=logistic.decision_function(X_test2)\n",
    "\n",
    "fpr2,tpr2,threshold2 = roc_curve(y_test2,y_score2,pos_label=1)\n",
    "roc_auc2=auc(fpr2,tpr2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.05, 1.05)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEKCAYAAAAb7IIBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl8VOX1+PHPCRD2QACFsASQRVkMVQFpcQkisipYRQFF\nad1+VSxaFLFoAasVq63r1w1QpFa0ighaIVFqpAgiVnaCSlQEDDshYQshnN8fMxknYZJMwty5mZnz\nfr3mZe6dZ+49l8R77r3PM88RVcUYY0zsiXM7AGOMMe6wBGCMMTHKEoAxxsQoSwDGGBOjLAEYY0yM\nsgRgjDExqrrbAQRLRGy8qjHGVIKqSqD1EXUHoKqVek2ePLnSn43Ulx1zbLzsmGPjdSrHXJaISgDG\nGGNCxxKAMcbEqJhIAKmpqW6HEHZ2zLHBjjk2OHXMUt4zolPauMhMYAiwU1VTSmnzDDAQOASMUdXV\npbRTJ2M1xphoJCKoS53ArwL9S3tTRAYC7VS1A3Ab8KLD8RhjjPFyNAGo6lJgfxlNhgKzvW1XAA1E\npKmTMRljjPFwuw+gBbDVb3m7d50xxhigsPCEY9uOmC+CVdbgNwbz4bcfuh2GMcZUzNGakH4ZqMDQ\nBejk0PeBup0AtgOt/JZbetcFNGXKFN/PqampQfWM28nfGBNxNreDBVdAbgOodhwuWhL0RzMyMsjI\nyAiqraOjgABEpA3wvqqeHeC9QcAdqjpYRHoBT6lqr1K2U6lRQDLV0/ntRPY0xjV/8w7qGG9/19Hk\nwIGj3HNPOjNmrAKgR4/mzJo1jM6dT6v0NssaBeToHYCIvAGkAo1F5EdgMhAPqKq+rKofisggEdmM\nZxjob5yMxxhjqrK0tCxmzFhFfHw1HnoolfHjf0X16s511TqaAFR1VBBtxjoZgzHGRIrhwzuzZs0F\nXHddyild9QfL7T4AY4wxXiLCI4/0Ddv+3B4GaowxMefAgaN8/PF3bodhCcAYY8IpLW0zXbu+wBVX\nzOHbb/e6Gos9AjLGmDAINMLH7enNLAEYY4zDli3byrXXvsO2bblhG+ETDEsAxhjjsCZN6rBnz+GQ\njOsPJUsAxhjjsI4dG7NkyRjOOSfJ9at+f5YAjDEmDHr0qHrzXFadVGSMMREuLW0zd9zx73KLsVcV\ndgdgTKi8Oxi+t8kHY1HJET4DB3ZgyJCOLkdVPksAxoRKuE/+bQeFd38moLS0zdx88/vFRvgMGNDe\n7bCCYgnAmFCzGTpjxrvvZnLVVf8CQjNzZ7hZAjDGmEoaNKgD55zTjGuv7VIlxvVXlCUAY4yppFq1\nqvPFF7dE3Im/SGRGbYwxYXbgwNGA6yP15A+WAIwxpky5ufnccssCunV7kdzcfLfDCSlLAMYYU4r0\n9Cy6dn2eGTNWkZ19kOXLt7odUkhZH4AxxpSQm5vP+PFpIa3NWxVZAjDGmBKWL9/qq807dWoq99wT\neSN8gmEJwBhjSujfvz2PPtqXyy/vSJcup7sdjmMsARhjTAATJ17gdgiOi757GmOMCVJubj7vv/+1\n22G4xhKAMSYmFY3w+fWv/8WqVdluh+MKewRkjIkpubn53HNPOtOnfwVA9+7NqVUrNk+FsXnUpuqz\nqZWNA1au3M5VV/2LrVs9M3dOmXIx997bOypH+ATDEoCpmiL15G9TNFdpzZvXJzc3n+7dmzNr1tCo\nHuETDEsApmqzqZVNCLVokcCSJb+hc+fTYvaq358lAGNMTElJaep2CFWGpUBjTNRJT8/ihhvmceKE\n3UGWxe4AjDFRo+QIn4ED2zNy5NkuR1V1WQIwxkSF9PQsbr55QbERPsOHd3E7rCrNEoAxJuItWrSZ\ngQP/CWAjfCrA8T4AERkgIptE5BsRuS/A+41FZKGIrBaRdSIyxumYjDHR5dJLz+DCC5P5y18uYfny\nm+zkHyRH7wBEJA54DugL/ASsFJH5qrrJr9lYYLWqDhSRJsDXIvK6qh53MjZjTPSoXj2OjIwxxMWJ\n26FEFKfvAHoC36rqFlUtAN4EhpZoswOo7/25PrDXTv7GmNLs3Xs44Ho7+Vec0wmgBeBfQ22bd52/\n6UAXEfkJWAOMczgmY0wEKqrN27nz8+zZEzgJmIqpCp3A9wNrVLWPiLQDPhKRFFU9WLLhlClTfD+n\npqaSmpoatiCNMe4pOcJn2bKtXHHFmW6HVSVlZGSQkZERVFtRde6LEiLSC5iiqgO8yxMBVdXH/Np8\nCDyiqp95lxcD96nqlyW2pZWJVaZ6bgt1sn0hJKL8zXs7b1NBxLRAtXlffdVG+FSEiKCqAZ+POX0H\nsBJoLyKtgWxgBDCyRJtM4FLgMxFpCnQEvnM4LuM2m+3TBGH9+l3MnBn9tXnd4mgCUNVCERkLpOPp\nb5ipqpkicpvnbX0ZeBR4VUTWAAJMUNV9TsZlqoBgTv42s2bM+9WvWvHMMwPp06eNXfU7wNFHQKFk\nj4CijD3iMSYsynoEZPdSxhjX5ebm89Zb690OI+ZUhVFAxpgY5j/CJympPhdd1NrtkGKGJQBjjCsC\njfBp0qSOy1HFFksAxpiwW7Uqm6FD3/SN67cRPu6wBGCMCbvk5AYcO1Zo4/pdZgnAGBN2jRvX4dNP\nx9CuXSO76neRJQBjjCvOPLOJ2yHEPEu9xhjHpKdnceWVb1FQUOh2KCYASwDGmJArmrmzf//Xee+9\nTcyatdrtkEwA9gjIGBNSJWfunDo1ld/85hy3wzIBWAIwxoTMp5/+QP/+rwM2c2cksARgjAmZiy5q\nzZAhHendu5WN648AQSUAEYkHklV1s8PxmEhiUzqbEkSEBQtGIGLlGSNBuelZRAYD64CPvMu/EJF5\nTgdmIsCpnvxtuueItmPHSUX7AOzkH0GCuQN4CDgf+ARAVVeLSHtHozKRxaZ0jilFc/j8618bWbfu\ndyQnN3A7JFNJwSSAAlXNKZHV7f94Y2JQyRE+K1ZsswQQwYJJAJkicg0QJyJtgd8DnzsbljGmKrHa\nvNEpmC76scB5wAngXSAfGOdkUMaYquWHH3J47bU1xMdX49FH+7Js2U128o8CwdwB9FfV+4D7ilaI\nyK/xJANjTAxISWnK9OmX0717czvxR5Fg7gAeCLBuUqgDMcZUbTfe+As7+UeZUu8ARKQ/MABoISJ/\n93srAc/jIGNMlMnNzeeddzby29/a1A2xoKxHQLuA9cBRYIPf+jxgopNBGWPCz3+ET5MmdbjiijPd\nDsk4rNQEoKqrgFUi8k9VPRrGmIwxYRRohE/79o1cjsqEQzCdwC1E5BGgM1CraKWqdnQsKmNMWKxf\nv4tBg/5ptXljVDAJYBbwMPAEMBD4DfZFMGOiQps2DalePc7G9ceoYBJAHVVNE5EnVDULeEBEvgQe\ndDg2Y4zD6tWLZ/HiG2jVqoFd9cegYBJAvojEAVki8v+A7UB9Z8NymM1iaYxP27aJbodgXBJMyr8b\nqItnCojewC3Ab50MynF28g8dm9EzIqSnZ9Gv3z84cqTA7VBMFVLuHYCqrvD+mAeMBhCRJCeDChub\nxdJEuZIjfF588UvuvvuXLkdlqooyE4CIpADtgExV3SQizfF8M3gIkByG+IwxlRSoNu+dd57vdlim\nCinrm8BTgZHAGuA8EXkbuAZ4DjgrPOEZYyrjyy9/stq8plxl3QFcDXRT1SMi0gjYCpytqt+FJzRj\nTGV1796c669PoUuX02xcvylVWQkgX1WPAKjqPhH5pjInfxEZADyFp8N5pqo+FqBNKvAkUAPYrap9\nKrofY0xxs2cPs/KMpkxlJYAzRKRoymcB2voto6q/Lm/j3uGjzwF9gZ+AlSIyX1U3+bVpAPwfcJmq\nbheRJpU4DmNi1tatB2jV6uSqXHbyN+UpKwFcVWL5uUpsvyfwrapuARCRN4GhwCa/NqOAuaq6HUBV\n91RiP8bEnKIRPq+/vo6vvrqVTp1OczskE2HKmgxucQi23wJP30GRbXiSgr+OQA0R+QSoBzyjqv8I\nwb6NiVolR/h89VW2JQBTYcF8E9hp1YFzgUvwfOFsuYgsV9XNJRtOmTLF93NqaiqpqalhCtGYqsFq\n85ryZGRkkJGREVRbpxPAdop/X6Cld52/bcAe75TTR0VkCdANKDMBGBOL9uw5zBtvrLeZO02pSl4c\nT506tdS2QScAEampqvkVjGUl0F5EWgPZwAg83y3wNx94VkSqATWB84G/Y4w5yRlnJPLaa8Po1KmJ\nXfWbU1ZuAhCRnsBMoAGQLCLdgJtV9c7yPquqhSIyFkjn52GgmSJym+dtfdn7DeM0YC1QCLysqhtP\n4ZiMiWpXX93Z7RBMlAjmDuAZPFM/vAegqmtEJOhx+qq6CDizxLqXSiw/gafegDEGz7P+115bzdix\nPW04p3FMMAkgTlW3lPgjLHQoHuf8zf4nMpHBf4RPQkJNbrzxF26HZKJUMAlgq/cxkHqf098JfONs\nWGFg0xibKibQCJ/u3Zu7HJWJZsEkgN/heQyUDOwEPvauiyw29bOpwr7+eg/9+v3DavOasAomARxX\n1RGOR2JMDGvbNpGGDWvRrFk9G9dvwiaYBLBSRL4G3gLeVdU8h2MyJubEx1dj4cLraNq0nl31m7Ap\n9y9NVdsBDwPnAetE5D0RsTsCYypJNfDjyBYtEuzkb8IqqL82VV2mqr/HM2VDLvBPR6MyJkqlp2dx\nwQWvkpNz1O1QjCk/AYhIPRG5TkTeB74AdgO/cjwyY6JIbm4+t9yygP79X2fZsq08++yK8j9kjMOC\n6QNYD7wP/FVV/+twPMZEnUC1ee+5x66hjPuCSQBnqOoJxyMxJgplZu622rymyiqrKPzfVHU8MFdE\nTuq1CqYimDGxrlOn07jzzp40b17fxvWbKqesO4C3vP+tTCUwY4zXM88MdDsEYwIq9XJEVb/w/thJ\nVRf7v4BO4QnPmMiRlbXP7RCMqZBg7kd/G2DdTaEOxJhIVTTC58wzn2PlypL1joypusrqA7gWTwGX\ntiLyrt9b9YEcpwMzJhKUHOGzfv0uevRo4XZYxgSlrD6AL4C9eMo4/p/f+jxglZNBGVPVWW1eEw1K\nTQCq+j3wPZ7ZP40xfg4fLmDu3EybudNEtLIeAX2qqheLyH7Afxio4Cnn2Mjx6Iypopo1q8cbb1xF\nq1YJdtVvIlZZj4CKyj42CUcgxkSaAQPaux2CMaekrGGgRd/+bQVUU9VC4JfAbUDdMMRmjOtyc/N5\n7LGlFBbal+FN9AnmoeV7eMpBtgNeBToAbzgalTFVQHp6Fl27Ps/EiYt59tkvyv+AMREmmLmATqhq\ngYj8GnhWVZ8RERsFZKJWoBE+/fqd4XJUxoReUCUhRWQ4MBoY5l1Xw7mQjHHP99/v5+KLZ1ltXhMT\ngkkAvwVuxzMd9Hci0haY42xYxrgjObkByckNrDaviQlSWnm6Yo1EqgNFQx42q+pxR6MKHIMGE+tJ\nn5sqAOjkin/WxKbduw+RmFjbrvpNVBARVFUCvVfuHYCIXAj8A9iO5zsAzURktKp+FtowjQkvVUXk\n5P8vTjvNBrmZ2BDMJc6TwCBV7a2qvwIGA087G5YxzkpPz+K8815mx46DbodijGuCSQDxqrqxaEFV\nM4F450Iyxjn+tXlXrdrBU0997nZIxrgmmE7gr0TkReB17/J12GRwJgJZbV5jigsmAfw/4PfABO/y\nf4FnHYvIGAf88EMOgwb9k8JCtZk7jfEqMwGIyNlAO2Ceqv41PCEZE3pt2jRk0qQLqV27ho3rN8ar\n1GGgIvJHPJW/vgJ6AA+p6isV3oHIAOApPP0NM1X1sVLa9QCWAdeq6rsB3rdhoMYYU0FlDQMt6zLo\nOiBFVYfjSQC/q8SO4/AUle8PdAFGishZpbSbBqRVdB/GlJSZudvtEIyJCGUlgHxVPQSgqrvLaVua\nnsC3qrpFVQuAN4GhAdrdCbwD7KrEPowBfh7h07nz83z88Xduh2NMlVdWH8AZfrWABWjnXxtYVX8d\nxPZbAFv9lrfhSQo+ItIcGKaqfUSk2HvGBKvkCJ/vvtvvdkjGVHllJYCrSiw/51AMTwH3+S0HfFYF\nMGXKFN/PqamppKamOhSSiRRWm9eY4jIyMsjIyAiqbVBzAVWWiPQCpqjqAO/yRDzlJB/za1N0ry54\nqo8dAm5V1QUltmWdwOYkOTlH6dr1eXbvPmwzdxoTwCnNBXSKVgLtRaQ1kA2MAEb6N1BV30TrIvIq\n8H7Jk78xpWnYsBZz5lxFo0a17arfmApyNAGoaqGIjAXS+XkYaKaI3OZ5W18u+REn4zHR6cILW7sd\ngjERKehHQCJSU1XzHY6nrP3bI6AYlpubz9//vpw//vFC4uOruR2OMRGjst8DKPpwTxFZB3zrXe4m\nIjYVhAmbotq8U6d+yiOPLHE7HGOiRjC9Zc8AQ4C9AKq6BujjZFDGQPGZO7duzaVHj+Zcc00Xt8My\nJmoE0wcQp6pbShTOKHQoHmMA+OmnPHr1mmG1eY1xUDAJYKv3C1oqItXwfGv3G2fDMrEuKakeZ5/d\n1GrzGuOgYBLA7/A8BkoGdgIfU4l5gYypCBHh9devpH79mnbVb4xDyk0AqroLz/h9Yxxx4oQSF3fy\nIIXExNouRGNM7AimKPx0AozPV9VbHYnIxJT09CzuumsRH3wwijPOSHQ7HGNiSjD31h8Di72vz4DT\nAde+D2Cig/8In8zMPTz55HK3QzIm5gTzCOgt/2UR+Qew1LGITNSz2rzGVA2VmQqiLdA01IGY2LBj\nx0GuuGIO+fmFNnOnMS4Lpg9gPz/3AcQB+4CJTgZlolezZvV49NG+5OcX2rh+Y1xW5lxA4vn2Vytg\nu3fViUpNyBMCNheQMcZUXKXnAvKecT9U1ULvy86iJmirV+9wOwRjTBmCuf9eLSLnOB6JiRpFI3zO\nOecl3nlno9vhGGNKUWofgIhUV9XjwDnAShHJwlOtS/DcHJwbphhNBCk5wmfnzoNuh2SMKUVZncBf\nAOcCV4QpFhPBDh48xt13L7LavMZEkLISgACoalaYYjERLC5O+PTTLTZzpzERpKwEcJqI/KG0N1X1\n7w7EYyJUnTo1mDPnKmrVqm5X/cZEiLISQDWgHt47AWPKc955zd0OwRhTAWUlgGxVfShskZiIkJub\nz6OP/pcHHriIunXj3Q7HGHMKyu0DMKaI/wifw4cLePrpgW6HZIw5BWUlgL5hi8JUabm5+Ywfn1Zs\nhM+tt57nclTGmFNVagJQ1X3hDMRUTXv3Huacc16y2rzGRKHKzAZqYkjjxnW46KLWfPPNXhvXb0yU\nsQRgyvXii0OoVau6XfUbE2UsARifwsITVKt28km+Xj0b7WNMNLJLOgNAWtpmzjzzOdat2+l2KMaY\nMLEEEOMOHDjKLbcsYMCAf5KVtZ+nn17hdkjGmDCxR0AxLC1tMzff/D7btnlG+Dz0UCrjx1ttXmNi\nhSWAGLV//xGGD3+bvLxj9OjRnFmzhtG582luh2WMCSNLADEqMbE2Tz01gN27DzF+vI3rNyYWWQKI\nYb/9rRV6MyaWOX7ZJyIDRGSTiHwjIvcFeH+UiKzxvpaKyNlOxxRrVqzYhpVzNsaU5GgCEJE44Dmg\nP9AFGCkiZ5Vo9h1wkap2Ax4GpjsZUywpGuHTq9dMZs5c5XY4xpgqxulHQD2Bb1V1C4CIvAkMBTYV\nNVDVz/3afw60cDimmFByhM/hwwVuh2SMqWKcTgAtgK1+y9vwJIXS3AwsdDSiKHfo0DHuuqt4bV4b\n4WOMCaTKdAKLSB/gN8AFpbWZMmWK7+fU1FRSU1MdjyvSxMdX43//yy42rt9G+BgTOzIyMsjIyAiq\nrTjZOSgivYApqjrAuzwRUFV9rES7FGAuMKC0IvQiopWJVaZ66tro5NjpBN24cTeAXfUbYxARVDVg\ngS+n7wBWAu1FpDWQDYwARpYILhnPyX90aSd/UzF24jfGBMPRBKCqhSIyFkjHM+Jopqpmishtnrf1\nZeBBoBHwvIgIUKCqZfUTGDwjfKZO/ZQHHriIRo1qux1ORGjTpg1btmxxOwxjHNG6dWt++OGHCn3G\n0UdAoWSPgH7mP8JnzJhf8OqrQ90OKSJ4b4XdDsMYR5T29+3mIyATQgcOHOWee9KLjfC5916bvM0Y\nUzmWACJEXl4+KSkv8uOPB2yEjzEmJCwBRIj69Wty+eUd+eKL7Tau3xgTEpYAIsjjj/ejRo1qdtVv\njAkJO5NUQQUFhQHX165dw07+JmZs3LiRHj16uB1GlXH++eeTmZkZ0m3a2aSKSUvbTIcOz7Js2dby\nG5uo0qZNG+rUqUNCQgJJSUmMHj2avLy8Ym2WLVtG3759SUhIIDExkaFDh550UsjLy+Ouu+6idevW\nJCQk0KFDB/7whz+wb9++cB7OKfvTn/7EhAkT3A6jXE8++SRJSUk0bNiQm2++mYKC0ufdWrp0KT17\n9qRBgwa0b9+e6dN/nvvytddeo3r16iQkJFC/fn0SEhJYsmSJ7/17772XBx98MLTBq2pEvDyhVhxT\nUKZU7rPhlJNzRG++eb7CFIUpOmrUXLdDijqV/RsKlzZt2uh//vMfVVXduXOnduvWTSdMmOB7f9my\nZVqvXj199tln9eDBg7p//3594IEHNDExUb///ntVVT127Jh2795dL7vsMt20aZOqqu7evVsfeeQR\nXbhwoWOxHz9+PKTby87O1saNG2t+fn6ViKc0ixYt0mbNmmlmZqbm5ORoamqq3n///QHbFhYW6mmn\nnabTp09XVdWVK1dqvXr1dO3ataqqOmvWLL3wwgtL3dfRo0e1UaNGunPnzoDvl/b37V0f+Lxa2htV\n7RXNCWDRom+1Zcu/K0zR+Pg/67Rp/9WCgkK3w4o6kZAAFi9e7FueMGGCDh482Ld84YUX6tixY0/6\n3MCBA/XGG29UVdXp06drs2bN9PDhw0Hvd/369dqvXz9t1KiRNmvWTB999FFVVR0zZow++OCDvnYZ\nGRnasmXLYvE+9thjmpKSorVq1dLHHntMr7766mLb/v3vf6/jxo1TVdUDBw7oTTfdpElJSdqyZUt9\n4IEH9MSJEwFjmj17tvbr16/YumnTpmm7du20fv362qVLF503b57vvVmzZmnv3r317rvv1saNG/vi\nnjlzpnbq1EkbNWqkAwYM0C1btvg+M27cOG3VqpUmJCRo9+7d9b///W/Q/2ZFRo0apZMmTfIt/+c/\n/9FmzZoFbPvTTz9pXFycHjlyxLeuR48e+uabb/qOoawEoKrar18/nT17dsD3KpMA7BGQyw4dOsbo\n0fPYti2XHj2as2rVbdx33wX2rN8Nf5PQvEJg27ZtLFy4kPPPPx+AI0eOsGzZMq6++uqT2l5zzTV8\n9NFHACxevJgBAwZQu3Zw3w4/ePAg/fr1Y9CgQWRnZ7N582b69u1banvPl/V/9uabb7Jw4UJycnIY\nMWIECxcu5NChQwCcOHGCt99+m+uuuw6AG2+8kfj4eL777jtWrVrFRx99xIwZMwLuZ926dZx55pnF\n1rVv357PPvuM3NxcJk+ezPXXX8/OnTt9769YsYL27duza9cuJk2axPz585k2bRrvvfceu3fv5sIL\nL2TkyJ9nounZsydr165l//79jBo1iuHDh3Ps2DEA5syZQ2JiIo0aNSIxMbHYz40aNWLbtm0AbNiw\ngW7duvm22a1bN3bt2sX+/ftPOqakpCRSUlJ45ZVXOHHiBMuXL+fHH3/kggt+nv9y1apVnH766Zx1\n1lk8/PDDnDhxotg2OnXqxJo1a0r57VScnWVcVrduPC+8MJhp0/qybNlNNrwzxg0bNoyEhASSk5Np\n164dkyZNAmDfvn2cOHGCpKSkkz6TlJTEnj17ANi7d2/ANqX54IMPSEpK4q677iI+Pp66detWqON1\n3LhxNG/enJo1a5KcnMy5557LvHnzAE8yKtrezp07WbhwIU8++SS1atWiSZMm3HXXXcyZMyfgdnNy\ncqhfv36xdVdddRVNmzYFYPjw4XTo0IEvvvjC936LFi24/fbbiYuLo2bNmrz00kvcf//9dOzYkbi4\nOCZOnMjq1avZutXTvzZq1CgaNmxIXFwcd999N/n5+Xz99dcAjBw5kv3797Nv3z72799f7Od9+/bR\nsmVLwJNAGzRo4IshISEBVT2p76bIyy+/zOTJk6lZsyYXX3wxjzzyCC1aeEqgXHzxxaxfv55du3Yx\nd+5c5syZw+OPP17s8/Xr1ycnJye4X04QbBhoFXDVVZ3dDsEAjHd/moj58+fTp08flixZwhVXXMH/\n/vc/evToQWJiInFxcWRnZ9OxY8din8nOzqZJkyYANG7cmOzs7KD3t3XrVtq1a1fpeItOhEVGjhzJ\nnDlzuP7665kzZw6jRo0C4Mcff6SgoMCXnIoeQSQnJwfcbmJi4kkn0dmzZ/Pkk0/65rs5dOiQL/EB\ntGrVqlj7LVu2MG7cOMaPH+/bp4iwfft2WrVqxRNPPMErr7zi+/fKy8srtr1g1KtXj9zcXN/ygQMH\nEJGTkhfATz/9xJAhQ5gzZw6XXnop3377LYMHD6Z58+YMHDiQNm3a+Np26dKFP/3pTzzxxBPcd9/P\nlXTz8vJo2LBhhWIsi90BhNHSpT9y/PiJ8huamKXeuVwuuugixo4d6xsFU6dOHX75y1/y9ttvn/SZ\nf/3rX1x66aUAXHrppaSlpXHkyJGg9teqVSuysgJPwlu3bl0OHz7sWw6UWEo+Eho+fDgZGRls376d\nefPm+RJAq1atqFWrFnv37vVdSefk5LB27dqA+05JSeGbb77xLf/444/ceuutPP/8874r8i5duhSb\n+6ZkLMnJybz00kvs27fPt8+DBw/Sq1cvli5dyuOPP84777zj217R1TvAG2+84RuJ4/8qWlf0CKhL\nly7FHsmsXr2apk2bkpiYeNIxLVu2jJYtW/p+Vx06dGDw4MEsXFh6DSz/4wPIzMws9sjplJXWOVDV\nXkRwJ7D/CJ/HHlvqaiyxrLJ/Q+FSshN49+7dWqdOHV2xYoWqqi5dutQ3CigvL0/37dunkyZN0sTE\nRN28ebOqqubn52vPnj114MCBumnTJj1x4oTu2bNH//KXvwQcBZSXl6fNmzfXp59+WvPz8zUvL8+3\nv+nTp2vx8SGLAAAPdElEQVSnTp103759mp2drb169dJWrVqVGm+RgQMHar9+/fTcc88ttn7YsGE6\nbtw4zc3N1RMnTmhWVpZ++umnAf8tdu7cqU2aNPGNAtq4caPWrl1bv/nmGy0sLNRXXnlFq1evrjNn\nzlTVwB2o8+bN065du+qGDRtUVTUnJ0fffvttVVX98MMPtUWLFrpjxw7Nz8/XqVOnavXq1QMeT1kW\nLVqkSUlJunHjRt23b5+mpqbqH//4x4BtN27cqHXr1vWN9Nq8ebO2b99eZ8yYoaqqCxcu9I3wyczM\n1K5du+qf//xn3+eLRgFlZ2cH3H5pf99YJ7B70tI207XrC8yYsYr4+GrUqGH/5CawklewTZo0YcyY\nMUybNg2A3r17k5aWxty5c0lKSqJt27asWbOGzz77zPcYJz4+no8//pizzjqLfv360aBBA3r16sXe\nvXt9Hcr+6tWrx0cffcSCBQto1qwZHTt29FWTGj16NCkpKbRp04YBAwYwYsSIMuMtMmrUKBYvXuzr\n/C0ye/Zsjh07RufOnWnUqBHDhw9nx44dAbdx+umnc8kll/Dee+8Bns7P8ePH06tXL5o1a8aGDRuK\ndZ4GMmzYMCZOnMiIESNo2LAhKSkpLFq0CID+/fvTv39/OnbsSNu2balTp85Jj5CC0b9/fyZMmECf\nPn1o27Yt7dq1K1a5cNCgQb7fX6dOnXjhhRe44447aNCgAX369GH48OHcdNNNgKfPJCUlhfr16zNk\nyBCuvvpq7r//ft+2FixYQJ8+fWjWrFmF4yyNTQftkCNHCvj97xdabd4qxKaDjiyZmZmMGTOGFStW\nuB1KlfDLX/6SmTNn0rlz4D5Dmw66CqlZszqbN++3mTuNqaROnTrZyd/P8uXLQ75NSwAOiYsTXnnl\nCo4cOW5X/caYKskSgIPatj15JIAxxlQV9kziFB04cJQ77/yQ7dtzy29sjDFViN0BnAL/2rzbt+fx\n7rvXuh2SMcYEzRJAJQSqzfvww5e4HJUxxlSMJYAKOnr0OOec8xLff59jI3yMMRHNEkAF1apVneuv\nT2HRos02rt8YE9HssrUSHnzwIpu50xiHWUnI4qwkZJgdPXo84HorzG6cYCUhi4uEkpAbNmxgwIAB\nnHbaaVSrVq3c9qtXr6Z79+6+abJLzu1fVnlJJ0pC2lmsFOnpWZx55nMsXPit26GYGCEi/Pvf/yY3\nN5c1a9awbt06Hn74Yd/7y5cvp3///lx55ZVkZ2fz/fffk5KSQu/evX1TJBcUFHDJJZeQmZlJeno6\nubm5LF++nCZNmhSbOz/UCgsLQ7q9HTt2kJGRwdChQ6tEPKWpUaMG1157La+88kq5bQsKChg2bBg3\n3HADOTk53HDDDQwdOpTjxz0Xmmlpafz1r3/lk08+YcuWLWRlZTF58mTf5y+//HI++eQTdu3aFboD\nKG2WuKr2IkyzgR44cLRYbd4rr3yzUvs1VU9l/4bCxUpC/ixSSkIW2bx5s8bFxZXZJj09vdi/n6pq\ncnKypqWlqWpw5SVDXRIy6juBKzIJXHp6FjffvICtW3OJj6/G1Kmp3HPPrxyMzlQlRRMHnqpQTDxY\nVBJy+PDhwM8lIf/85z+f1Paaa67xVQ6rbEnICRMm8MEHH1BQUMDGjRtLbV9aScjGjRuzc+dOHnro\nIQ4dOkTdunV9JSHnz58PeEpCJiUl8d1333Hw4EGGDBlCcnIyt9xyy0n7KaskZNOmTXn77be5/vrr\nycrK8lUJW7FiBaNGjWLXrl0UFBT4SkJ+8MEHtG/fnmnTpjFy5Eg+++wzwFMScsqUKSQkJPD0008z\nfPhwtmzZQnx8PHPmzOH2228vNsFa0c8iwtq1a08qhlOeDRs2kJKSUmxdt27d2LBhA5dddhkbNmxg\n2LBhxd4rKi9ZVF+gqCTk6NGjK7Tv0tgjIK/8/OPccsv7bN3qqc371Ve3MnGi1eY14WUlIT0ipSRk\nRZQsHwmeEpJF/TzBlJe0kpAOqVmzOjNmXM7//pfNPffYuP5YFO4pwwOxkpAekVISsiJKlo8ETwnJ\nokQXTHlJKwnpoH792tlVv3FV0eMGKwkZGSUhK6JLly4nHe/atWvp2rWr7/3yyktGXElIYACwCfgG\nuK+UNs8A3wKrgV+U0iZgB0dlfPLJ93rkSEHItmciQyj/hpxgJSF/FiklIVU9pRo3bNigIqJHjx71\nxVzSsWPHtE2bNvrMM89ofn6+Pv3009qmTRstKPCci8orLxlxJSFFJA54DugPdAFGishZJdoMBNqp\nagfgNuBFp+LJzc3nllsW0KfPazz00KdO7caYSrGSkD+LlJKQW7ZsoXbt2px99tmICLVr1+ass34+\nxfmXhKxRowbvvfcer732GomJicyePZv58+dTvXp1X0xllZeMuJKQItILmKyqA73LE/Fko8f82rwI\nfKKqb3mXM4FUVd1ZYlt6KrGWHOHz8MN9uPfe3pXenok8VhIyslhJyOIisSRkC2Cr3/I2oGc5bbZ7\n1+0kBI4dK+SOO/5dbObOV18dSpcup4di88YYh1hJyOKsJGQl1KgRx+7dh4uN67dOXmOMcT4BbAf8\nx3m19K4r2aZVOW0Aij0PS01NJTU1tdwARIQXXxzC3r2H7arfGBP1MjIyfP045XG6D6Aa8DXQF8gG\nvgBGqmqmX5tBwB2qOtjbZ/CUqvYKsK1T6gMwxvoATDSrcn0AqlooImOBdDzfOZipqpkicpvnbX1Z\nVT8UkUEishk4BPzGyZiMMcZ4OHoHEEp2B2BOld0BmGhW5e4AjKlKWrduXerYdWMiXevWrSv8GbsD\nMMaYKFbWHUBMjIcMtkc8mtgxxwY75tjg1DFbAohSdsyxwY45NlgCMMYYE1KWAIwxJkZFVCew2zEY\nY0wkKq0TOGISgDHGmNCyR0DGGBOjLAEYY0yMiqoEICIDRGSTiHwjIveV0uYZEflWRFaLyC/CHWOo\nlXfMIjJKRNZ4X0tF5Gw34gylYH7P3nY9RKRARH4dzvicEOTfdqqIrBKR9SLySbhjDLUg/rYbi8hC\n7//L60RkjAthhoyIzBSRnSISuFAyDpy/SqsVGWkvPMlsM9AaqIGnvvBZJdoMBP7t/fl84HO34w7D\nMfcCGnh/HhALx+zXbjHwAfBrt+MOw++5AbABaOFdbuJ23GE45snAo0XHC+wFqrsd+ykc8wXAL4C1\npbwf8vNXNN0B9AS+VdUtqloAvAkMLdFmKDAbQFVXAA1EpGl4wwypco9ZVT9X1QPexc/xVFuLZMH8\nngHuBN4BdoUzOIcEc8yjgLmquh1AVfeEOcZQC+aYdwD1vT/XB/aq6vEwxhhSqroU2F9Gk5Cfv6Ip\nAQQqP1nyZFda+clIFcwx+7sZWOhoRM4r95hFpDkwTFVfAKJh9rdgfs8dgUYi8omIrBSR0WGLzhnB\nHPN0oIuI/ASsAcaFKTa3hPz8ZbOBxggR6YOn1sIFbscSBk8B/s+MoyEJlKc6cC5wCVAXWC4iy1V1\ns7thOep+YI2q9hGRdsBHIpKiqgfdDixSRFMCCGn5yQgRzDEjIinAy8AAVS3rFjMSBHPM3YE3xTP3\ncxNgoIgUqOqCMMUYasEc8zZgj6oeBY6KyBKgG57n6JEomGPuDTwCoKpZIvI9cBbwZVgiDL+Qn7+i\n6RHQSqC9iLQWkXhgBFDyf/gFwA0A3vKTOaq6M7xhhlS5xywiycBcYLSqZrkQY6iVe8yqeob31RZP\nP8DtEXzyh+D+tucDF4hINRGpg6eTMJPIFcwxZwKXAnifhXcEvgtrlKEnlH7HGvLzV9TcAWgMlp8M\n5piBB4FGwPPeK+ICVe3pXtSnJshjLvaRsAcZYkH+bW8SkTRgLVAIvKyqG10M+5QE+Xt+FHhVRNbg\nOWlOUNV97kV9akTkDSAVaCwiP+IZ5RSPg+cvmwrCGGNiVDQ9AjLGGFMBlgCMMSZGWQIwxpgYZQnA\nGGNilCUAY4yJUZYAjDEmRlkCMFWGiBSKyFfeKY2/8n6JrbS2rUVkXQj2+Yl3yuHVIvJfEelQiW3c\nJiLXe3++UUSa+b33soicFeI4l4lIpyA+M05Eap3qvk30sgRgqpJDqnquqp7j/e+P5bQP1ZdYRqrq\nL/DMtPhERT+sqi+p6uvexTH4TdClqreq6qaQRPlznC8Dfw2i/V1AnRDt20QhSwCmKjnpK/DeK/0l\nIvKl99UrQJvOIrLCe9ew2jsxGCJynd/6F7zfhC5rv0uAos/29X5ujYjMEJEa3vXTvAVXVovIX73r\nJovIeBG5Cs88RK97P1vLe+V+rvcuwXfS9t4pPFPJOJcDZ/ht63kR+UI8RVEme9fdCTQHPhGRxd51\nl3nvHr4Ukbe8U0aYGGYJwFQltf0eAc31rtsJXKqq3fHMB/NsgM/9P+ApVT0Xzwl4m/exy7XAr7zr\nTwDXlbP/K4B1IlITeBUYrqrd8BQk+Z2INMIzzXRX75X4w36fVVWdi2cislHeO5ijfu/PBa70W74W\nz4R1lYlzIJ7iL0X+6J3eoxuQKiJdVfVZPBOFpapqXxFpDEwC+nr/Lf8HjC9nPybKRc1cQCYqHPae\nBP3FA8+Jp/xdIRDoGf1yYJKItALeVdXNItIXz/TIK71X1LXwJJNA/ikiR4Af8BSSORP4zm/yvNeA\n24H/A46IyAzg33iqjQVy0hW8qu4RkSwR6Ylnhs4zVXWZiNxRwThrAg2BFL/1I0TkFjz/PzcDOgPr\nKT6xWC/v+s+8+6mB59/NxDBLAKaquxvYoaopIlINOFKygarOEZHPgSHAv70ThgnwmqpOCmIfo1R1\nVdGC92o50Em80HsC7wsMB8Z6fw7WW3iu9jcB84p2V9E4vY+S7gXGiUgbPFfy56lqroi8iieJlCRA\nuqqWd3dhYog9AjJVSaBn3w2AbO/PNwDVTvqQSFtV/d772GMBnqvjxcDVInKat01iGaOKSu73a6C1\niBQ9Zx8NfOp9Zt5QVRcBf6D4VXiRPCChlP3Mw1PWbwSeEodUMs4/AUO9dzwJwEEgTzxTIg/0a5/r\nF8vnQG+//pE6lRnxZKKLJQBTlQQa1fM8MEZEVuGZ7/1QgDbXeDtmVwFdgNmqmgk8AKSLZ7rgdDyP\nR8rdp6rm45lq9x3vZwuBF/GcTD/wrluC5+6kpFnAi0WdwP7bV9UcPHPYJ6vql951FY7T27fwNJ5n\n/2vxFEzPBF4Hlvp9ZjqwSEQWe2sE/waY493PMjyPukwMs+mgjTEmRtkdgDHGxChLAMYYE6MsARhj\nTIyyBGCMMTHKEoAxxsQoSwDGGBOjLAEYY0yMsgRgjDEx6v8DQmK+/qWxlHwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9c83cf7b90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "lw=2\n",
    "plt.plot(fpr,tpr,color='darkorange',lw=lw,label='ROC curve (area=%0.2f)' % roc_auc)\n",
    "plt.plot(fpr2,tpr2,color='green',lw=lw,label='ROC curve (area=%0.2f)' % roc_auc2)\n",
    "plt.plot([0,1],[0,1],color='navy',lw=lw,linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xlim(-0.05,1.05)\n",
    "plt.ylim(-0.05,1.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### External validation for two model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testset=pd.read_table('data/breast_cancer_test.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.819444444444\n",
      "precision :0.9\n",
      "recall : 0.428571428571\n",
      "f1_score : 0.58064516129\n"
     ]
    }
   ],
   "source": [
    "test_result=external_val_classif(testset,dataset1,logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.875\n",
      "precision :0.3\n",
      "recall : 0.6\n",
      "f1_score : 0.4\n"
     ]
    }
   ],
   "source": [
    "test_result2=external_val_classif(testset,dataset2,logistic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

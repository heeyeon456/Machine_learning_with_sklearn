{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Tree model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information Criteria\n",
    " ### Uncertainty(불확실성) <br/>\n",
    "  - related to our **surprise** at an event<br/><br/>\n",
    "ex) 내일 해가 뜰 껏이다.   => 그렇게 놀랍지 않음<br/><br/>\n",
    "    내일 해가 뜨지 않을 것이다.  => 매우 놀라운 일<br/><br/>\n",
    "    Uncertainly는 event의 확률과 반비례한다.<br/><br/><br/>\n",
    " ### Entropy <br/>\n",
    "    - A measure of uncertainly of a random variable in terms of bits(log2)<br/>\n",
    "     **        = Average Uncertainty**<br/><br/>\n",
    "ex) 해가 뜬다<br/><br/>\n",
    "    A : 내일 해가 뜬다.          p(A) = p1<br/>\n",
    "    B : 내일 해가 뜨지 않는다.    p(B) = p2<br/>\n",
    "    <center>**Average Uncertainty** about sun rising<br/></center><br/>\n",
    "    $$= p(A)Uncetainty(A) + p(B)Uncertainty(B) $$<br/>\n",
    "    $$= -p_1log_2{p_1}-p_2log_2{p_2} = -\\sum p_ilog{p_i} = Entropy $$\n",
    "    <br/>\n",
    "    - Information theory : optimal length code assigns -log p bits tp message having probability p\n",
    "### Entropy  maximum at maximum randomness \n",
    "\n",
    "<img style=\"float: right;\" src=\"picture/entropy.png\"><br/>\n",
    "Example : Coin Toss<br/><br/>\n",
    "P(heads) = 0.1     => not very random<br/>\n",
    "H(x) = 0.47 bits<br/><br/><br/>\n",
    "P(heads) = 0.5    => Completely random <br/>\n",
    "H(x) = 1 bits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Conditional Entropy <br/>\n",
    "    - Expected entropy of conditional distribution averaged over the conditioning random variable<br/><br/>\n",
    "$$   H(Y|X) = \\sum_{x_i}p(x_i)H(Y | X=x_i) = -\\sum_{x_i}\\sum_{y_i}p(x_i,y_i)log{p(y_i|x_i)}  $$\n",
    "<br/>\n",
    "* ### Relative Entropy <br/>\n",
    "    - A measure of distance between two probability distributions <br/><br/>\n",
    "    - 두 확률분포가 얼마나 비슷한지 (두 변수가 얼마나 비슷한지) <br/><br/>\n",
    "$$ D(p(X)||q(X)) = \\sum_{x_i}p(x_i)log\\frac{q(x_i)}{p(x_i)} $$\n",
    "<br/>\n",
    "* ### Mutual Information <br/>\n",
    "    - Relative entropy between joint distribution p(X,Y) and product distribution p(X)p(Y)<br/><br/>\n",
    "    - 두 변수간의 interaction을 고려햇을 때와 단순히 두 변수를 독립으로 가정했을 때와의 uncertainty감소량 <br/><br/>\n",
    "    - 두 변수간의 interaction이 얼마나 있는지\n",
    "<br/><br/>\n",
    "$$ I(X;Y)=D(p(X,Y)|p(X)p(Y))$$<br/>\n",
    "$$ = \\sum_{x_iy_i}p(x_i,y_i)log\\frac{p(x_i,y_i)}{p(x_i)p(y_i)}$$<br/>\n",
    "$$= H(X) - H(X|Y) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Information Gain ** \n",
    "- Gain(S, A) = expected reduction in entropy due to sorting on A\n",
    "$$ Gain(S,A) = Entropy(S) - \\sum_{v\\in Values(A)}\\frac{|S_v|}{|S|}Entropy(S_v)  $$\n",
    "- Selecting next attribute using information gain\n",
    "<img style=\"float: left;\" src=\"picture/decisiontree.png\"><br/>\n",
    "=> Humity가 더 좋은 attribute이다. 왜냐하면 humity로 분류함으로써 더 information gain이 크고 데이터의 불확실성이 줄어들기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "* Decision tree는 feature들의 조건을 tree구조로써 각 node에 대응시켜서 각 입력 변수들이 root node로 부터 leaf node에 해당하는 feature값의 조건을 가질 때 특정 label을 가진다고 예측하는 방법의 supervised learning의 일종이다.\n",
    "<img style=\"float: left;\" src=\"picture/decisiontree2.png\"><br/>\n",
    "* decision tree에서의 learning은 각각의 데이터를 information이 더 큰 feature를 분할 기준으로 선택해 나눠가는 과정이다. 이 과정은 분할로 인해서 더이상 새로운 예측값이 추가되지 않고나 부분 집합의 노드가 목표 변수와 같은 값을 지닐 때까지 반복된다.<br/><br/>\n",
    "* 많이 쓰는 알고리즘으로 ID3(Iterative Dichotomiser 3)가 있다\n",
    "    1) initial open node 만들기<br/>\n",
    "    2) initial node에 instance넣기<br/>\n",
    "    3) open node가 없을 때까지 반복<br/>\n",
    "    open node선택은 best variable을 정의하고(Information Gain이용) -> <br/>\n",
    "    선택된 variable마다 instance sort -> sorted item을 branch 밑으로 넣기(+이면 +, -이면 -)\n",
    " <br/><br/>   \n",
    "* Decision tree의 문제점<br/>\n",
    "지금의 data에 대해선 잘 예측할 수 있지만 real world data에 대해서 inconsistent할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from numpy.random import RandomState\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tools import rmse_cal,mae_cal,cor_cal,mean_cal,frange,\\\n",
    "                    accuracy,precision,recall,aupr,f1_score,make_binary\n",
    "from validation import classification_cv,regression_cv,external_val_reg,\\\n",
    "                        external_val_classif, test_preprocessing, cal_external_auc,cal_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset=pd.read_table('data/breast_cancer_svc.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt=DecisionTreeClassifier(criterion=\"entropy\",splitter=\"random\",min_samples_split=20,\n",
    "                          random_state=RandomState(None),presort=True)\n",
    "#criteria : 정보 획득 정도를 entropy를 이용할껀지 지니계수를 이용할껀지\n",
    "#splitter : 각 노드에서 분리를 할 때 사용하는 방법( best : 최선의 결과로 자름 \n",
    "#            / random :random하게 자른 것 중 최선을 택함\n",
    "#max_feature : tree를 만들면서 분리 기준을 만들때 고려할 최대 feature 개수 제한\n",
    "#max_depth : tree의 depth제한\n",
    "# min_samples_split : 노드를 분리시킬때 필요한 최소한의 sample개수 제한\n",
    "# min_weight_fraction_leaf : sample weight\n",
    "# max_leaf_node : 최대 leaf 노드의 개수\n",
    "#presort  : 가장 좋은 split을 빨리 찾기 위해 데이터를 미ㅣ리 sorting할껀지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_result=classification_cv(10,dt,dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def cal_auc(inputdf,model,testratio):\n",
    "    #preprocessing for ROC curve\n",
    "\n",
    "    input_data=inputdf.iloc[:,1:].transpose()\n",
    "    X_data=input_data.iloc[:,:-1].values\n",
    "    y_data=input_data.iloc[:,-1]\n",
    "    y_data=make_binary('normal','cancer',y_data)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=testratio\n",
    "                                                    ,random_state=RandomState(None))\n",
    "    model.fit(X_train,y_train)\n",
    "    \n",
    "    #각 sample들을 분류하기 위한 decision을 내리는 함수\n",
    "    y_score = model.fit(X_train, y_train).predict(X_test)\n",
    "    fpr,tpr,threshold = roc_curve(y_test,y_score,pos_label=1)\n",
    "    roc_auc=auc(fpr,tpr)\n",
    "    Aupr = aupr(y_test,y_score)\n",
    "    \n",
    "    return y_score,fpr,tpr,threshold,roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_roc(inputdf,model,testratio):\n",
    "\n",
    "    plt.figure()\n",
    "    lw=2\n",
    "    y_score, fpr,tpr,threshold ,roc_auc= cal_auc(inputdf,model,testratio)\n",
    "\n",
    "    plt.plot(fpr,tpr,color='darkorange',lw=lw,label='ROC curve (area=%0.2f)' % roc_auc)\n",
    "    plt.plot([0,1],[0,1],color='navy',lw=lw,linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "draw_roc(dataset,dt,.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "External validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testset=pd.read_table('data/breast_cancer_test.tsv',sep='\\t')\n",
    "test_result=external_val_classif(testset,dataset,dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression problem\n",
    "- y값을 int데이터가 아닌 floating point로 보고 decision tree를 이용해서 fitting한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reg_data=pd.read_table('data/blood_age_selected_lasso.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt_reg=DecisionTreeRegressor(criterion='mse', splitter='random',min_samples_split=20,\n",
    "                             presort=True,random_state=RandomState(None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_result=regression_cv(10,dt_reg,reg_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data=pd.read_table('data/blood_age_test.tsv',sep='\\t')\n",
    "test_result=external_val_reg(test_data,reg_data,dt_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Ensemble method**는 더 좋은 성능을 얻기 위해서 여러가지 learning algorithm을 함께 쓰는 방법을 의미한다.<br/><br/>\n",
    "supervised learning algorithm은 보통 특정 문제에 대해서 가장 좋은 prediction을 할 수 있는 적절한 가설(hypothesis function)을 가설 공간(hyphothesis space)에서 찾고자 하는 목표를 가진다.<br/>\n",
    "앙상블(ensemble)방법은 더 나은 가설을 찾기 위해 여러 가설(hypothesis function)들을 결합한다.<br/>\n",
    "- 보통 앙상블 방법은 모델들 사이에 성능이 큰 차이를 보일 경우 더 나은 결과를 가져온다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble종류\n",
    "### ** Bayes optimal classifier ** <br/>\n",
    "이 방법은 classification problem에서 이용하는 방법으로 모든 가설 공간(hypothetis space)안에 있는 모든 가설(hypothesis function)의 앙상블한다.<br/>\n",
    "각 hypothesis는 hypothesis가 참일때 training dataset을 특정 class에 대해서 얼마나 잘 설명해줄 수 있는 데(얼마나 많이 설명해 줄 수 있는지)에 대한 확률에 비례하게 각 class에 투표한다.<br/> 모든 hypothesis 의 결과를 합했을 때 class들 중 더 높은 값을 같은 class의 결과로 예측한다. <br/>\n",
    "\n",
    "$$ y=argmax_{c_j\\in C}\\sum_{h_j\\in H}P(c_j|h_j)P(T|h_j)P(h_j)  $$\n",
    "<br/>\n",
    "- ex) p(h1|D)=0.4, p(-|h1)=0, p(+|h1)=1<br/>\n",
    "    p(h2|D)=0.3, p(-|h2)=1, p(+|h2)=0 <br/>\n",
    "    p(h3|D)=0.3, p(-|h3)=1, p(+|h3)=0 <br/>\n",
    "    <br/>\n",
    "    $ \\sum_{h_j \\in H}P(+|h_j)](h_j|D)=0.4 $ <br/>\n",
    "    $ \\sum_{h_j \\in H}P(-|h_j)](h_j|D)=0.6 $ <br/><br/>\n",
    "    따라서 해당 데이터 집단은 - class로 예측한다\n",
    "<br/><br/>\n",
    "### ** Bootstrap aggregating(bagging) ** <br/>\n",
    " bootstrap은 전체 training data에서 training data의 개수와 동일한 개수의 sample을 복원추출(resample with replacement)하는 것을 여러번 반복해서 통계적 추정을 함으로써, 추정한 통계량이 얼마나 신뢰도를 같는지 구하는 방법이다. <br/><br/> bagging은 bootstrap 분석을 사용해서 여러 가설함수를 만든 다음 각각을 동일한 weight를 줌으로써 학습을 하는 앙상블 기법이다<br/><br/>\n",
    "이때 regression의 경우는 각각의 모델(가설)의 결과를 평균내어 가장 좋은 방법을 얻고, classification같은 경우는 각 모델에서 가장 많이 나온 결과를 투표하여 결과를 예측한다.예시로써 random forest classifier가 있다.<br/><br/>\n",
    "![bagging](picture/bagging.png)\n",
    "### ** Boosting ** <br/>\n",
    "boosting은 잘못 분류된 개처들에 관심을 가지고 이들을 더 잘 분류하고자 하는 아이디어에서 시작되었다. 따라서 boosting은 잘못 분류된 개체들(weak learner)에 집중하여 새로운 분류 규칙을 만드는 단계를 반복하는 과정이다. 즉, 약한 예측모형들을 결합하여 더 강한 예측 모형을 만드는 것이 바로 boosting algorithm이다. boosting방법은 예측 변수를 순차적으로 생성하고자 한다. 따라서 처음 raw data의 객처들은 동일한 weight를 가지고 시작하지만 학습을 함으로써 예측 변수에 의해 잘못 분류된 개체들에 대해서는 높은 weight가 부여되고, 잘 분류된 객체들에는 낮은 weight를 부여하여 오분류된 객체들이 더 잘 분류되도록 하고자 한다.\n",
    "![boost](picture/boosting.png)\n",
    "<br/>\n",
    "대표적인 boosting algorithm에는 Adaboost알고리즘이 있다. 이 algorithm은 error가 큰 learner에 대한 weight를 높임으로써 계속 classifier를 업데이트 한다. 또 다른 boosting algorithm에는 Gradient Boosting algorithm이 있다. \n",
    "![adaboost](picture/AdaBoost.png)\n",
    "[참고](https://m.blog.naver.com/PostView.nhn?blogId=muzzincys&logNo=220201299384&proxyReferer=https%3A%2F%2Fwww.google.co.kr%2F)\n",
    "<br/><br/>\n",
    "### ** Stacking ** <br/>\n",
    "staking 은 다양한 학습 알고리즘을 통해 여러 모델들을 조합한다. 모델들을 조합할 classifier를 선택할 때 meta-learner를 이용해 어떤 classifier를 신뢰할 수 있는지를 학습, 좋은 classifier를 찾아내어 여러 모델들을 조합한다. \n",
    "![stacking](picture/stacking.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bagging 방법을 이용한 ensemble방법의 하나로 여러 tree들이 bootstraped sample들을 이용해서 만들어지고, 다수의 tree가 판정한 결과로 예측한다<br/><br/>\n",
    "또 random forest에서 split은 feature들의 random subset중 가장 좋은 split이 선택된다.<br/> 이러한 random ness에 의해서 bias는 약간 증가하지만 variance가 감소하기 때문에 overfitting을 방지하고 더욱 general한 모델을 얻을 수 있다. \n",
    "\n",
    "### Measure\n",
    "- **oob error(Out-of-bag error)** : bagging방법을 이용했을때 prediction error를 measure하는 방법 중 하나이다.<br/>\n",
    "oob는 특정 training sample a에 대해서 a를 가지고 있지 않는 모델(tree)들의 예측값의 error값의 평균이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset=pd.read_table('data/breast_cancer_svc.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=20, criterion='entropy',  min_samples_split=10,\n",
    "                            max_features='auto', bootstrap=True, oob_score=True,\n",
    "                            n_jobs=10, random_state=RandomState(None), warm_start=True)\n",
    "#oob_score : bootstrap 방법을 이용했을 때 generalized accuracy를 구하는 방법으로 이 measure를 구할건지\n",
    "#warm_start  이전에 함수를 calling했을 때 썼던 solution들을 다시 이용하고, 더 많은 estimator를 그다음에 새로 추가하는 옵션이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/ensemble/forest.py:303: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.983502538071\n",
      "precision :0.863157894737\n",
      "recall : 1.0\n",
      "f1_score : 0.926553672316\n"
     ]
    }
   ],
   "source": [
    "cv_result=classification_cv(10,rf,dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97042253521126765"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testset=pd.read_table('data/breast_cancer_test.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.847222222222\n",
      "precision :0.2\n",
      "recall : 0.4\n",
      "f1_score : 0.266666666667\n"
     ]
    }
   ],
   "source": [
    "ext=external_val_classif(testset,dataset,rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reg_data=pd.read_table('data/blood_age_selected_lasso.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_reg=rf = RandomForestRegressor(n_estimators=20, criterion='mse',  min_samples_split=10,\n",
    "                            max_features='auto', bootstrap=True, oob_score=True,\n",
    "                            n_jobs=10, random_state=RandomState(None), warm_start=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_resul=regression_cv(10,rf_reg,reg_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data=pd.read_table('data/blood_age_test.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "external=external_val_reg(test_data,reg_data,rf_reg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

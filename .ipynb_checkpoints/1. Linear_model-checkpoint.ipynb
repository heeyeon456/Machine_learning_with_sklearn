{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Model\n",
    "## 1.Least Square\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "어떠한 데이터가 주어졌을 때 그 데이터는 수식으로 표현될 수 있다.\n",
    "예를 들어 집값이라는 반응변수가 주어졌을 때 이는 교통편, 주변환경 시설, 집의 넓이, 기본제공 가구목록 등 여러가지 설명변수로 표현될 수 있다.\n",
    "그리고 우리는 모든 데이터를 관찰할 수 없기 때문에 내가 관찰한 데이터를 가지고 집값(y)라는 변수는 여러가지(x)값들과 주어진 설명변수로 표현할 수 없는 값(error)값으로 표현할 수 있다. \n",
    "\n",
    "$$ y  = \\sum_{i=0}^n a_ix_i+e_i $$\n",
    "\n",
    "하지만 우리는 설명변수가 주어졌을 때 모든 데이터에 대한 반응변수를 예측할 수 있는 general한 식을 얻고 싶다. \n",
    "**머신러닝**은 이처럼 probably approximately correct한 function을 주어진 데이터를 가지고 찾아나가는 과정을 의미한다.\n",
    "General model을 찾아나가는데 중요한 것은 most probable한 parameter를 찾아가는 것이다.\n",
    "여기서 가장 간단한 접근 방법이 **least square**접근법이다.\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{a} = argmin(f-\\hat{f}) = argmin_\\theta (Y-aX)^2\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tools import rmse_cal,mae_cal,cor_cal,mean_cal,frange,\\\n",
    "                    accuracy,precision,recall,aupr,f1_score,make_binary\n",
    "from validation import classification_cv,regression_cv,external_val_reg,\\\n",
    "                        external_val_classif, test_preprocessing, cal_auc, \\\n",
    "                        draw_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##dataset\n",
    "dataset=pd.read_table('data/blood_age_selected_mutual_info.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset=dataset.T.fillna(dataset.mean(axis=1)).T\n",
    "dataset.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_t=dataset.iloc[:,1:].transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_data = data_t.iloc[:,:-1]\n",
    "y_data = data_t.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reg = LinearRegression(n_jobs=20)\n",
    "cv_result=regression_cv(10,reg,dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df=pd.read_table('data/blood_age_test.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_result=external_val_reg(test_df,dataset,reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principle of parsimony (Occam's Razor) ##\n",
    "---\n",
    "- 간결한 모델일 수록 좋다.<br/>\n",
    "어떤 실험 결과나 현상에 대해 설명할 수 있는 변수들이 많은 경우 그것을 가장 잘 설명할 수 있는 변수는 결국 간단한 설명 혹은 최소한 의 설명이 되는 변수로 이루어진 모델이다.<br/><br/>\n",
    "- **subset selection** : 중요한 변수를 선정하고, 중요하지 않은 변수를 버리는 작업<br/>\n",
    "머신러닝에서의 feature selection<br/><br/>\n",
    "- **shrinkage** : 중요하지 않은 변수에 해당하는 Coefficient의 절대값을 낮추는 것\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Regularization ##\n",
    "---\n",
    "=shrinkage\n",
    "\n",
    "기계학습에서는 **bias - variance trade off** 문제가 종종 발생한다.<br/><br/>\n",
    "**bias**는 데이터 내의 모든 정보를 잘 반영하지 않아 잘못된 것을 학습하는 경향이다. (= **Underfitting**) <br/>\n",
    "**Variance**는 데이터 내에 존재하는 error나 noise까지 학습에 반영되어 training data에 너무 적합한 모델이 학습되는 경향이다. 이는 **overfitting**과 관련이 있다. -> 앞 0.basis예시 참고 <br/>\n",
    "<br/><br/><br/>\n",
    "특히 overfitting 문제는 machine learning에서 종종 발생하고, 이를 해결하기 위한 방법으로는 **regularization**이 있다.<br/><br/>\n",
    "\n",
    "예를 들어 4차 함수의 linear regression에 대한 hypothesis function이 다음과 같다고 하자<br/>\n",
    "$$ y=\\theta_0 + \\theta_1 x+ \\theta_2 x^2 + \\theta_3 x^3 + \\theta_4 x^4 $$ <br/>\n",
    "하지만 이 함수는 데이터를 설명하는데에 있어서 overfitting문제를 가지고 있다고 할 때, 3승과 4승에 해당하는 항의 영향을 줄여 overfitting문제를 개선하고자 한다. <br/><br/>\n",
    "이를 해결하기 위해서는 cost function을 수정하면 된다. <br/>\n",
    "$$ min \\frac{1}{2m} \\sum_{i=1}^{m}(h_0(x^{(i)})-y^{(i)})^2 + 1000\\theta _3^2 + 1000\\theta _4^2 $$<br/>\n",
    "\n",
    "cost function을 이렇게 수정한다면 최소한의 cost를 가지는 각 파라미터 세타 값을 구할 때에 x^3과 x^4의 계수는 매우 작아질 것이다.\n",
    "이러한 방식으로 x^3과 x^4에 해당하는 계수의 값을 줄여 overfitting을 방지할 수 있다. <br/>\n",
    "<br/><br/>\n",
    "이를 일반적인 수식으로 나타내면 다음과 같다.<br/>\n",
    "$$ min_\\theta \\frac{1}{2m}[ \\sum_{i=1}^{m}(h_0(x^{(i)})-y^{(i)})^2 + \\lambda \\sum_{i=1}^{n}\\theta_j^2]  $$<br/>\n",
    "\n",
    "위의 cost function에서 두번째 항을 regularization term이라고 하고, lambda를 regularization parameter라고 한다.<br/><br/>\n",
    "lambda가 너무 크면 모든 항들에 대하서 너무 많이 penalty가 적용되므로 model이 데이터를 잘 설명하지 못하는 underfitting문제가 발생할 것이다.<br/><br/> 하지만 lambda가 너무 작으면 모든 항들에 대해서 penalty가 적용되지 않으므로 overfitting문제가 계속 발생할 것이다. <br/><br/>\n",
    "따라서 적절한 lambda를 선택하는 것이 매우 중요하다.<br/><br/>\n",
    "[참고](http://gnujoow.github.io/ml/2016/01/30/ML4-Regularization/)<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression\n",
    "---\n",
    "ridge regression에서는 L2 norm인 Euclidean norm을 사용하여 패널티를 주는 방식을 선택하여 사용한다.<br/>\n",
    "\n",
    "\n",
    "$$L(\\beta)=\\frac{1}{2}(y-X\\beta )^T(y-X\\beta )+\\frac{\\lambda }{2}||\\beta ||^2_2 $$\n",
    "\n",
    "$$ ||\\beta||^2 = \\sqrt{\\beta _1^2 + \\beta _2^2 + ... +\\beta _n^2} $$\n",
    "\n",
    "ridge regression의 cost function은 기존의 회귀분석의 RSS(Residual Sum of Square)항과 패널티 항 두 항의 합으로 이루어져 있다.<br/><br/>\n",
    "이러한 ridge regression은 기존 선형회귀의 RSS를 최소화하는 beta값이더라고 구한 beta값의 크기가 너무 크면 그에 대한 패널티를 부여해 cost function값을 높여버린다.  <br/>\n",
    "\n",
    "$$ min_w||Xw-y||_2^2+\\alpha ||w||_2^2 $$<br/>\n",
    "\n",
    "alpha는 shrinkage의 정도를 조절해주는 parameter<br/>\n",
    "\n",
    "[참고](http://r-programming.club/14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tools import rmse_cal,mae_cal,cor_cal,mean_cal,frange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf=KFold(n_splits=10,shuffle=True)\n",
    "ridge=RidgeCV(alphas=(0.1, 1.0, 10.0), fit_intercept=True, scoring=None ,cv=kf,gcv_mode='auto')\n",
    "# alpha : number of alpha to test 여기서는 0.1부터 1까지 10개의 alpha값을 cross validation으로 고르고자 한다.\n",
    "# fit_intercept : 이모델의 intercept(절편을 계산할껀지)\n",
    "# normalize : regression모델을 만들기 전에 normalize할껀지\n",
    "#gcv_mode : generalized cross validation option "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv_result=regression_cv(10,ridge,dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ridge.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reg_coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_result=external_val_reg(test_df,dataset,ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression ##\n",
    "---\n",
    "Lasso regression은 ridge regression의 장점인 회귀계수 축소를 통해 예측 정확도를 높이고(shrinkage), 동시에 영향력이 적은 회귀계수의 값을 쉽게 0으로 만드는 변수 선택의 기능이 있어(subset selection)의 기능이 있어 해석력을 높여준다.<br/>\n",
    "Lasso regression은 l1 norm을 사용해서 패ㄴㄹ티를 주는 방식을 이용한다.<br/><br/>\n",
    "\n",
    "Lasso regression의 추정량의 식은 다음과 같다.<br/>\n",
    "\n",
    "$$ argmin_{\\beta_1,...,\\beta_p}\\left \\{\\sum_{i=1}^{n}(Y_i-\\beta_0-\\sum_{j=1}^{p}\\beta_jx_{ij})^2 + \\lambda \\sum_{j=1}^{p}|\\beta_j|  \\right \\}  $$ <br/>\n",
    "\n",
    "위 식은 다음과 같은 제약조건이 주어진 최소화(minimization)문제로 표시할 수 있다.<br/><br/>\n",
    "$$argmin_{\\beta_1,...,\\beta_p}\\left \\{\\sum_{i=1}^{n}(Y_i-\\beta_0-\\sum_{j=1}^{p}\\beta_jx_{ij})^2\\right \\} subject to \\sum_{j=1}^{p}|\\beta_j|\\leq t$$<br/>\n",
    "\n",
    "위 식의 제약 조건인 t는 회귀계수 값에 대하여 축소 정도를 조절하는 tuning parameter이다. <br/><br/>이 tuning parameter t값이 줄어들지 않으면 중요하지 않은 변수의 회귀계수 값은 축소되면서 순서대로 0으로 만들어져 변수 선택이 되는 효과가 생긴다.<br/><br/>\n",
    "만약 t값이 충분히 커지면 회귀 계수에 대한 제약이 없어지므로 RSS부분만 남아 Lasso 회귀추정량이 최소제곱 추정량이 된다.<br/><br/>\n",
    "\n",
    "\n",
    "$$ min_w||Xw-y||_2^2+\\alpha ||w||_1 $$\n",
    "\n",
    "||w||는 l1-norm의 parameter vector<br/>\n",
    "\n",
    "[참고](http://m.blog.daum.net/naturelove87/154)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "\n",
    "from numpy.random import RandomState\n",
    "from numpy import nonzero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lasso=LassoCV(eps=0.01, n_alphas=100, fit_intercept=True, max_iter=1000, tol=0.0001, cv=kf, n_jobs=10, positive=False, random_state=RandomState(None), selection='random')\n",
    "#eps : alpha_min / alpha_max, 비교해야할 alpha의 최소값과 최대값의 비율\n",
    "#n_alphas : regularization과정에서 test할 alpha의 개수\n",
    "#tol : optimization을 언제까지 진행깔껀지, 만약 performance가 tol보다 적게 향상됬다면 optimazation을 하지 않는다,\n",
    "#positive : True이면 regression coefficient가 양수가 되도록 조정한다\n",
    "#random_state : random state를 특정 값으로 설정해 놓으면 pseudo random generator가 특정 값에 해당하는 random number를 generate해준다\n",
    "#특정 seed에 대해서 생성되는 random number는 항상 동일하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[참고 : pseudo random number generator](https://en.wikipedia.org/wiki/Pseudorandom_number_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv_result=regression_cv(10,lasso,dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lasso.fit(X_data, y_data)\n",
    "tmp=dataset.iloc[:-1,:]\n",
    "print('number of reduced feature using lasso :' + str(len(tmp[lasso.coef_!=0])))\n",
    "print('original number of feature : '+str(len(tmp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_result=external_val_reg(test_df,dataset,lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic Net Regression ##\n",
    "---\n",
    "ElasticNet은 L1과 ㅣ2를 모두 regularizer로 이용하는 linear regression model이다.<br/><br/> 이 조합은 Lasso에서 weight를 0으로 만드는 subset selection 방법을 통해 sparse한 모델을 만드는 특징과 ridge에서의 shrinkage를 이용한 regularization property를 유지하는 특징을 지닌다. <br/><br/>이 방법에서는 L1과 L2의 값을 l1_ratio라는 parameter를 이용해 그 정도를 조절한다.<br/><br/><br/>\n",
    "ElasticNet의 추정량 식은 다음과 같다<br/>.\n",
    "\n",
    "$$ min_w\\frac{1}{2n}||Xw-y||^2_2+\\alpha \\beta ||w||_1+\\frac{\\alpha (1-\\beta )}{2}||w||_2^2 $$<br/>\n",
    "\n",
    "여기서 alpha는 penalty를 얼마나 줄것인가에 대한 parameter이고 beta(l1_ratio)는 lasso와 ridge를 얼마만큼의 비율로 적용할 것인가에 대한 parameter이다.<br/><br/>\n",
    "\n",
    "ElasticNet은 서로 연관이 되어잇는 multiple feature를 다루는데 유용하고, dataset개수에 비해 feature수가 매우 많을 때 가장 잘 learning되는 regression model로 알려져있다.<br/><br/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from numpy.random import RandomStatea\n",
    "from numpy import nonzero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def elastic_net_l1(input_data,l1):\n",
    "    \"\"\"elastic net 10-fold crossvalidation\"\"\"\n",
    "    \n",
    "    kf=KFold(n_splits=10,shuffle=True)\n",
    "    input_t=input_data.ix[:,1:]\n",
    "    final_input=input_t.transpose()\n",
    "    \n",
    "        \n",
    "    pred=pd.DataFrame()\n",
    "    real=pd.DataFrame()\n",
    "    \n",
    "    elastic_net=ElasticNetCV(cv=kf, fit_intercept=True, random_state=RandomState(None), selection='random',\n",
    "                             max_iter=100000,l1_ratio=l1)\n",
    "    \n",
    "    prediction=pd.DataFrame(columns=['predict','real'])\n",
    "\n",
    "    rmse=0\n",
    "    cor=0\n",
    "\n",
    "    for train, test in kf.split(final_input):\n",
    "            \n",
    "        x_train=final_input.iloc[train,:-1].astype('float64').values\n",
    "        y_train=final_input.iloc[train,-1].astype('float64').values\n",
    "        elastic_net.fit(x_train,y_train)\n",
    "    \n",
    "        x_test=final_input.iloc[test,:-1].astype('float64').values\n",
    "        y_test=final_input.iloc[test,-1].astype('float64').values\n",
    "        \n",
    "        pred=pred.append(pd.DataFrame(elastic_net.predict(x_test)))\n",
    "        real=real.append(pd.DataFrame(y_test))\n",
    "        \n",
    "        prediction=pd.concat([pred,real],axis=1)\n",
    "\n",
    "        rmse=rmse+rmse_cal(prediction.iloc[:,0],prediction.iloc[:,1])\n",
    "        cor=cor+cor_cal(prediction.iloc[:,0],prediction.iloc[:,1])[0]\n",
    "    \n",
    "    rmse=rmse/10\n",
    "    cor=cor/10\n",
    "    \n",
    "    return l1,rmse,cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_l1(input_data):\n",
    "    \"\"\"elastic net has two parameter : alpha(amount of regularization) and l1_ratio(ratio of ridge and lasso regularization)\n",
    "       optimal alpha can be found automatically using ElasticNetCV.\n",
    "       we should find optimal l1 ratio using 10-fold cross validation.\"\"\"\n",
    "       \n",
    "    \"\"\"choose elastic net l1 ratio\"\"\"\n",
    "    \n",
    "    list=['l1','rmse','cor']\n",
    "    by_l1_ratio=pd.DataFrame(columns=list)\n",
    "    num=0\n",
    "    for l in frange(0.1,1,0.1):\n",
    "        el=elastic_net_l1(input_data,l)\n",
    "        by_l1_ratio.loc[num]=el\n",
    "         \n",
    "        num=num+1\n",
    "    print(by_l1_ratio)\n",
    "    \n",
    "    return by_l1_ratio.loc[by_l1_ratio['rmse'].idxmin()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l1_ratio=find_l1(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kf=KFold(n_splits=10,shuffle=True)\n",
    "elasticnet=ElasticNetCV(cv=kf, fit_intercept=True, random_state=RandomState(None), selection='random',\n",
    "                             max_iter=100000,l1_ratio=l1_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "elasticnet.fit(X_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp=dataset.iloc[:-1,:]\n",
    "print('number of reduced feature using ElasticNet :' + str(len(tmp[elasticnet.coef_!=0])))\n",
    "print('number of reduced feature using lasso :' + str(len(tmp[lasso.coef_!=0])))\n",
    "print('original number of feature : '+str(len(tmp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_result=external_val_reg(test_df,dataset,elasticnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression ##\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistic Regression은 종속 변수가 categorical할 때 쓰는 회귀 모델이다.<br/><br/>\n",
    "- Logistic Regression의 목적은 두개의 범주가 주어졌을 때 데이터를 이용해서 두 그룹 중 어떤 그룹에 속하는지 분류하고자 한다.\n",
    "<br/><br/><br/>\n",
    "우선 binary data가 주어졌을 때 이 binary data는 sample size가 1인 binomial trial에서부터 온 값이라고 가정한다.<br/><br/>\n",
    "$$ P(y)=p^y(1-p)^{1-y} $$<br/>\n",
    "binary data를 확률로 나타낼 수 있다면 오즈비(Odds Ratio)도 구할 수 있다.<br/><br/>\n",
    "**Odds Ratio** = 성공확률/실패확률 = p / 1-p<br/><br/>\n",
    "$$ Odds\\, Ratio = \\frac{p}{1-p} $$<br/>\n",
    "$$ Logit(p) = ln\\frac{p}{1-p} $$\n",
    "<br/><br/><br/>\n",
    "- logistic regression은 classification문제를 다루기 때문에 binary data가 A라는 class에 속할 확률(p)가 0.5이상이면 A class에 분류하고자 하고, 그렇지 않으면 B class에 분류하고자 한다.<br/><br/>\n",
    "- 따라서 logistic regression에서는 y가 나올 확률(p)를 선형회귀(ax+b)를 이용해서 계산하고자 한다.<br/><br/>\n",
    "1)logit함수를 선형회귀로 표현 $$ ln\\frac{p}{1-p} = ax+b $$<br/>\n",
    "2)양변에 e를 취함 $$ \\frac{p}{1-p}=e^{ax+b} $$<br/>\n",
    "3)양변에 1을 더함 $$ \\frac{1}{p}=\\frac{1+e^{ax+b}}{e^{ax+b}} $$<br/>\n",
    "4)역수를 취해서 확률을 계산하는 수식을 만듬 $$ p = \\frac{e^{ax+b}}{1+e^{ax+b}} $$<br/><br/>\n",
    "- 이렇게 y가 A class에 속한 확률을 나타낸 식을 로지스틱함수(logistic function)고 하고 이를 나타낸 곡선을 logistic curve라고 부른다.<br/><br/>\n",
    "<img src=\"picture/logistic_regression.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "따라서 A class가 나올 확률 p가 0이면 x값은 -무한대가 되고, p=1이면 x값은 무한대가 되기 때문에 \n",
    "p=0에 가까울수록 0으로 보내주고, p가 1에 가까우면 1로 보내주어서 classification을 수행한다. 그리고 이러한 threshold를 적절하게 조정해가면서 찾게 된다.<br/><br/>\n",
    "$$ p=0 \\rightarrow  log(\\frac{p}{1-p})=-\\infty $$\n",
    "$$ p=1 \\rightarrow  log(\\frac{p}{1-p})=\\infty $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import KFold\n",
    "from numpy.random import RandomState\n",
    "from numpy import nonzero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model : Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf=KFold(n_splits=10,shuffle=True)\n",
    "logistic = LogisticRegressionCV(Cs=10, cv=kf, fit_intercept=True, dual=False, penalty='l2', \n",
    "        solver='sag', tol=0.0001, max_iter=100, n_jobs=20, verbose=0, refit=True, random_state=RandomState(None))\n",
    "#Cs : C값은 regularization정도와 반비례하고, Cs는 1e-4 and 1e4사이의 로그 스케일 값 중 몇개의 값을 테스트 할것 인지를 나타낸다.  \n",
    "#penalty : l1 norm또난 ㅣ2 norm을 이용할 것인지\n",
    "#solver : optimization algorithm들 \n",
    "#        liblinear : 데이터셋이 작을 때 좋다고 한다, sag : 클 때 좋다고 한다, \n",
    "##newton-cg, sag, lbfgs : multi class에서 쓰고, ㅣ2 penalty에서만 다룰수 있다.\n",
    "#dual : l2일 때만 True옵션이 가능하다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison for two feature selection method\n",
    "dataset1 : feature selected by mutual information using knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset1=pd.read_table('data/breast_cancer_mutual_info.tsv',sep='\\t')\n",
    "input_data=dataset1.iloc[:,1:].transpose()\n",
    "X_data=input_data.iloc[:,:-1].values\n",
    "y_data=input_data.iloc[:,-1]\n",
    "y_data=make_binary('normal','cancer',y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.927664974619\n",
      "precision :0.473684210526\n",
      "recall : 0.865384615385\n",
      "f1_score : 0.612244897959\n"
     ]
    }
   ],
   "source": [
    "cv_test=classification_cv(10,logistic,dataset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#preprocessing for ROC curve\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=.2,random_state=RandomState(None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=10, class_weight=None,\n",
       "           cv=KFold(n_splits=10, random_state=None, shuffle=True),\n",
       "           dual=False, fit_intercept=True, intercept_scaling=1.0,\n",
       "           max_iter=100, multi_class='ovr', n_jobs=20, penalty='l2',\n",
       "           random_state=<mtrand.RandomState object at 0x7fa2fd976190>,\n",
       "           refit=True, scoring=None, solver='sag', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#각 sample들을 분류하기 위한 decision을 내리는 함수\n",
    "y_score=logistic.decision_function(X_test)\n",
    "fpr,tpr,threshold = roc_curve(y_test,y_score,pos_label=1)\n",
    "roc_auc=auc(fpr,tpr)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset2 : feature selection using svc with l1 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset2=pd.read_table('data/breast_cancer_svc.tsv',sep='\\t')\n",
    "input_data2=dataset2.iloc[:,1:].transpose()\n",
    "X_data2=input_data2.iloc[:,:-1].values\n",
    "y_data2=input_data2.iloc[:,-1]\n",
    "y_data2=make_binary('normal','cancer',y_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 1.0\n",
      "precision :1.0\n",
      "recall : 1.0\n",
      "f1_score : 1.0\n"
     ]
    }
   ],
   "source": [
    "cv_result=classification_cv(10,logistic,dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Preprocessing for ROC curve\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_data2, y_data2, test_size=.2,random_state=RandomState(None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=10, class_weight=None,\n",
       "           cv=KFold(n_splits=10, random_state=None, shuffle=True),\n",
       "           dual=False, fit_intercept=True, intercept_scaling=1.0,\n",
       "           max_iter=100, multi_class='ovr', n_jobs=20, penalty='l2',\n",
       "           random_state=<mtrand.RandomState object at 0x7fa2fd976190>,\n",
       "           refit=True, scoring=None, solver='sag', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic.fit(X_train2,y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#각 sample들을 분류하기 위한 decision을 내리는 함수\n",
    "y_score2=logistic.decision_function(X_test2)\n",
    "\n",
    "fpr2,tpr2,threshold2 = roc_curve(y_test2,y_score2,pos_label=1)\n",
    "roc_auc2=auc(fpr2,tpr2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa2fa009810>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEPCAYAAABGP2P1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nERERERERERERERERERERERERkXjx/7knEqw17JBxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa2fa009b90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "lw=2\n",
    "plt.plot(fpr,tpr,color='darkorange',lw=lw,label='ROC curve (area=%0.2f)' % roc_auc)\n",
    "plt.plot(fpr2,tpr2,color='green',lw=lw,label='ROC curve (area=%0.2f)' % roc_auc2)\n",
    "plt.plot([0,1],[0,1],color='navy',lw=lw,linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### External validation for two model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testset=pd.read_table('data/breast_cancer_test.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.819444444444\n",
      "precision :0.9\n",
      "recall : 0.428571428571\n",
      "f1_score : 0.58064516129\n"
     ]
    }
   ],
   "source": [
    "test_result=external_val_classif(testset,dataset1,logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.875\n",
      "precision :0.3\n",
      "recall : 0.6\n",
      "f1_score : 0.4\n"
     ]
    }
   ],
   "source": [
    "test_result2=external_val_classif(testset,dataset2,logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
